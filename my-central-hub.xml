This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: **/*.log, **/*.json, **/.gitignore, node_modules/**, thumbnails/**, **/dist/**, **/build/**
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
__mocks__/
  logger.ts
config/
  server.config.ts
core/
  httpParser.test.ts
  httpParser.ts
  parser.test.ts
  parser.ts
  router.test.ts
  router.ts
  server.test.ts
  server.ts
entities/
  http.ts
  sendResponse.test.ts
  sendResponse.ts
modules/
  app-metrics/
    app_gallery-generator/
      index.ts
      metricsController.ts
      metricsService.ts
    index.ts
    metricsController.test.ts
    README.md
  embeddings/
    embedding.service.ts
    embeddings.handler.ts
  file-hosting/
    fileHostingController.ts
    fileHostingService.test.ts
    fileHostingService.ts
    index.ts
  file-streaming/
    fileService.ts
    fileStreamingController.test.ts
    fileStreamingController.ts
    index.ts
routes/
  embeddings.routes.ts
  file-hosting.routes.ts
  files.routes.ts
  index.ts
  metrics.routes.ts
  stream.routes.ts
utils/
  helpers.test.ts
  helpers.ts
  httpHelpers.ts
  logger.ts
  mimeTypes.ts
embedding_service_helper.py
fileHosting.stress.test.ts
fileStreaming.stress.test.ts
global.d.ts
main.ts
requirements.txt
router.stress.test.ts
server.stress.test.ts
setupJest.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="config/server.config.ts">
import dotenv from 'dotenv';
import path, { join } from 'path';
import { Logger } from '../utils/logger';
const logger = new Logger();
dotenv.config();
export const config = {
  port: process.env.PORT ? parseInt(process.env.PORT, 10) : 8080,
  publicDir: process.env.PUBLIC_DIR
    ? join(process.cwd(), process.env.PUBLIC_DIR)
    : join(process.cwd(), 'public'),
  mediaDir: process.env.MEDIA_DIR
    ? join(process.cwd(), process.env.MEDIA_DIR)
    : join(process.cwd(), 'media'),
  headerTimeoutMs: process.env.HEADER_TIMEOUT_MS
    ? Math.max(parseInt(process.env.HEADER_TIMEOUT_MS, 10), 0)
    : 5000,
  bodyTimeoutMs: process.env.BODY_TIMEOUT_MS
    ? Math.max(parseInt(process.env.BODY_TIMEOUT_MS, 10), 0)
    : 10000,
  dbPath: process.env.DB_PATH ? process.env.DB_PATH : join(process.cwd(), 'data', 'metrics.db'),
  features: {
    metrics: true,
    fileHosting: true,
    fileStreaming: true,
  },
  logging: {
    level: process.env.LOG_LEVEL || 'info',
    format: process.env.LOG_FORMAT || 'json',
    logDir: process.env.LOG_DIR || join(process.cwd(), 'logs'),
  },
  embedding: {
    pythonExecutable: process.env.PYTHON_EXECUTABLE || 'python3',
    pythonScriptPath:
      process.env.PYTHON_SCRIPT_PATH ||
      path.resolve(process.cwd(), 'python', 'embedding_service_helper.py'),
    pythonLogPath: process.env.PYTHON_LOG_PATH,
    modelArgs: [
    ],
    defaultModel: 'openai/clip-vit-base-patch32',
    defaultNumFrames: 20,
    enableAugmentation: false,
    inactivityTimeoutMs: 5 * 60 * 1000,
    scriptTimeoutMs: 15 * 60 * 1000,
    debug: false,
    log: false,
  },
  testMode: true,
};
if (!config.testMode) {
  logger.info(`Server configuration:`);
  logger.info(`- Port: ${config.port}`);
  logger.info(`- Public Directory: ${config.publicDir}`);
  logger.info(`- Media Directory: ${config.mediaDir}`);
  logger.info(`- Header Timeout: ${config.headerTimeoutMs}ms`);
  logger.info(`- Body Timeout: ${config.bodyTimeoutMs}ms`);
  logger.info(`- Database Path: ${config.dbPath}`);
}
</file>

<file path="core/httpParser.ts">
import { IncomingRequest } from '../entities/http';
import { URL } from 'url';
import logger from '../utils/logger';
enum ParserState {
  REQUEST_LINE,
  HEADERS,
  BODY,
  CHUNK_SIZE,
  CHUNK_BODY,
  CHUNK_TRAILER,
  DONE,
  ERROR,
}
const ALLOWED_METHODS = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'HEAD', 'OPTIONS'];
const MAX_HEADER_BYTES = 8192;
const MAX_HEADERS = 100;
const MAX_BODY_BYTES = 10 * 1024 * 1024;
const CRLF = Buffer.from('\r\n');
export class HttpRequestParser {
  protected buffer = Buffer.alloc(0);
  private state = ParserState.REQUEST_LINE;
  private headers: Record<string, string> = {};
  private headersMap = new Map<string, string[]>();
  private bodyChunks: Buffer[] = [];
  private method = '';
  private httpVersion = '';
  private url!: URL;
  private contentLength = 0;
  private remainingBody = 0;
  private isChunked = false;
  private invalid = false;
  private lastHeaderKey: string | null = null;
  /**
   * Returns the number of pending bytes in the parser buffer.
   */
  public getPendingBytes(): number {
    return this.buffer.length;
  }
  feed(data: Buffer): IncomingRequest | null {
    this.buffer = Buffer.concat([this.buffer, data]);
    try {
      while (true) {
        // REQUEST_LINE
        if (this.state === ParserState.REQUEST_LINE) {
          const idx = this.buffer.indexOf('\r\n');
          if (idx === -1) return null;
          const requestLine = this.buffer.subarray(0, idx).toString('utf8');
          this.buffer = this.buffer.subarray(idx + 2);
          const parts = requestLine.split(' ');
          if (parts.length !== 3) {
            this._setError('Invalid request line: ' + requestLine);
            return this._errorResponse();
          }
          const [method, reqPath, version] = parts;
          if (!ALLOWED_METHODS.includes(method)) {
            this._setError('Unsupported method: ' + method);
            continue;
          }
          if (!version.startsWith('HTTP/')) {
            this._setError('Invalid HTTP version: ' + version);
            continue;
          }
          this.method = method;
          this.httpVersion = version;
          try {
            this.url = new URL(reqPath, 'http://placeholder');
          } catch {
            this._setError('Malformed URL: ' + reqPath);
            continue;
          }
          this.state = ParserState.HEADERS;
        }
        if (this.state === ParserState.HEADERS) {
          const idx = this.buffer.indexOf('\r\n\r\n');
          let headersRaw = '';
          if (idx === -1) {
            // immediate blank line → zero headers
            if (this.buffer.subarray(0, 2).equals(CRLF)) {
              this.buffer = this.buffer.subarray(2);
            } else {
              if (this.buffer.length > MAX_HEADER_BYTES) {
                this._setError('Headers too large');
                return this._errorResponse();
              }
              return null;
            }
          } else {
            headersRaw = this.buffer.subarray(0, idx).toString('utf8');
            this.buffer = this.buffer.subarray(idx + 4);
          }
          const lines = headersRaw.split('\r\n');
          let headerCount = 0;
          for (const line of lines) {
            if (line.trim() === '') continue;
            // support folded headers per RFC7230 §3.2.4
            if (line.startsWith(' ') || line.startsWith('\t')) {
              if (this.lastHeaderKey) {
                const prev = this.headers[this.lastHeaderKey];
                this.headers[this.lastHeaderKey] = prev + ' ' + line.trim();
                this.headersMap.set(
                  this.lastHeaderKey,
                  (this.headersMap.get(this.lastHeaderKey) || []).concat(
                    this.headers[this.lastHeaderKey],
                  ),
                );
                continue;
              } else {
                this._setError('Invalid header folding');
                return this._errorResponse();
              }
            }
            const colon = line.indexOf(':');
            if (colon === -1) {
              this._setError('Invalid header line: ' + line);
              continue;
            }
            const key = line.slice(0, colon).trim().toLowerCase();
            const value = line.slice(colon + 1).trim();
            this.headers[key] = value;
            this.headersMap.set(key, [...(this.headersMap.get(key) ?? []), value]);
            this.lastHeaderKey = key;
            headerCount++;
            if (headerCount > MAX_HEADERS) {
              this._setError('Too many headers');
              return this._errorResponse();
            }
          }
          if (this.invalid) {
            return this._errorResponse();
          }
          if (this.httpVersion === 'HTTP/1.1' && !this.headers['host']) {
            this._setError('Missing Host header');
            return this._errorResponse();
          }
          if (
            this.headers['transfer-encoding'] &&
            this.headers['transfer-encoding'].toLowerCase() === 'chunked'
          ) {
            this.isChunked = true;
            this.state = ParserState.CHUNK_SIZE;
          } else if (this.headers['content-length']) {
            this.contentLength = parseInt(this.headers['content-length'], 10);
            if (isNaN(this.contentLength) || this.contentLength < 0) {
              this._setError('Invalid Content-Length');
              continue;
            }
            this.remainingBody = this.contentLength;
            this.state = this.contentLength > 0 ? ParserState.BODY : ParserState.DONE;
          } else {
            this.state = ParserState.DONE;
          }
        }
        if (this.state === ParserState.BODY) {
          this.contentLength = parseInt(this.headers['content-length'], 10);
          if (isNaN(this.contentLength) || this.contentLength < 0) {
            this._setError('Invalid Content-Length');
            continue;
          }
          if (this.contentLength > MAX_BODY_BYTES) {
            this._setError('Request body too large');
            continue;
          }
          this.remainingBody = this.contentLength;
          if (this.buffer.length < this.remainingBody) return null;
          this.bodyChunks.push(this.buffer.subarray(0, this.remainingBody));
          this.buffer = this.buffer.subarray(this.remainingBody);
          this.remainingBody = 0;
          this.state = ParserState.DONE;
        }
        if (this.state === ParserState.CHUNK_SIZE) {
          const idx = this.buffer.indexOf('\r\n');
          if (idx === -1) return null;
          const line = this.buffer.subarray(0, idx).toString('utf8');
          this.buffer = this.buffer.subarray(idx + 2);
          const chunkSize = parseInt(line, 16);
          if (isNaN(chunkSize)) {
            this._setError('Invalid chunk size: ' + line);
            continue;
          }
          if (chunkSize === 0) {
            this.state = ParserState.CHUNK_TRAILER;
          } else {
            this.remainingBody = chunkSize;
            this.state = ParserState.CHUNK_BODY;
          }
        }
        if (this.state === ParserState.CHUNK_BODY) {
          if (this.remainingBody > MAX_BODY_BYTES) {
            this._setError('Chunk body too large');
            continue;
          }
          if (this.buffer.length < this.remainingBody) return null;
          const chunk = this.buffer.subarray(0, this.remainingBody);
          this.bodyChunks.push(chunk);
          this.buffer = this.buffer.subarray(this.remainingBody);
          this.remainingBody = 0;
          if (this.buffer.length < 2 || !this.buffer.subarray(0, 2).equals(CRLF)) {
            this._setError('Missing CRLF after chunk');
            continue;
          }
          this.buffer = this.buffer.subarray(2);
          this.state = ParserState.CHUNK_SIZE;
        }
        if (this.state === ParserState.CHUNK_TRAILER) {
          if (this.buffer.length === 0 || this.buffer.equals(CRLF)) {
            this.buffer = Buffer.alloc(0);
            this.state = ParserState.DONE;
            continue;
          }
          const idx = this.buffer.indexOf('\r\n\r\n');
          if (idx === -1) return null;
          this.buffer = this.buffer.subarray(idx + 4);
          this.state = ParserState.DONE;
        }
        if (this.state === ParserState.DONE) {
          const leftover = this.buffer;
          const finalBody = this.bodyChunks.length ? Buffer.concat(this.bodyChunks) : undefined;
          const request = {
            method: this.method,
            path: this.url.pathname,
            query: Object.fromEntries(this.url.searchParams.entries()),
            headers: this.headers,
            headersMap: this.headersMap,
            httpVersion: this.httpVersion,
            url: this.url,
            body: finalBody,
            raw: '',
            ctx: {},
            invalid: this.invalid,
          };
          this.reset();
          this.buffer = leftover; // restore leftover for next request
          return request;
        }
        // ERROR
        if (this.state === ParserState.ERROR) {
          const errReq = this._errorResponse();
          this.reset();
          return errReq;
        }
      }
    } catch (err) {
      this._setError(`Error during parsing: ${(err as Error).message}`);
      const errReq = this._errorResponse();
      this.reset();
      return errReq;
    }
  }
  private _setError(message: string): void {
    logger.error(message);
    this.invalid = true;
    this.state = ParserState.ERROR;
  }
  /** Build a minimal invalid IncomingRequest */
  private _errorResponse(): IncomingRequest {
    return {
      method: '',
      path: '',
      query: {},
      headers: {},
      headersMap: new Map(),
      httpVersion: '',
      url: new URL('http:
      body: undefined,
      raw: '',
      ctx: {},
      invalid: true,
    };
  }
  reset(): void {
    this.buffer = Buffer.alloc(0);
    this.state = ParserState.REQUEST_LINE;
    this.headers = {};
    this.headersMap = new Map();
    this.bodyChunks = [];
    this.method = '';
    this.httpVersion = '';
    this.url = new URL('http:
    this.contentLength = 0;
    this.remainingBody = 0;
    this.isChunked = false;
    this.invalid = false;
    this.lastHeaderKey = null;
  }
}
</file>

<file path="core/parser.ts">
import { IncomingRequest } from '../entities/http';
import { URL } from 'url';
const ALLOWED_METHODS = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'HEAD', 'OPTIONS'] as const;
const MAX_HEADERS = 1000;
function addHeader(map: Map<string, string[]>, key: string, value: string) {
  const k = key.toLowerCase();
  const list = map.get(k) ?? [];
  list.push(value);
  map.set(k, list);
}
export const parser = {
  parse(raw: string): IncomingRequest {
    const dummyUrl = new URL('http://placeholder/');
    const earlyReturn = (): IncomingRequest => ({
      url: dummyUrl,
      path: '',
      query: {},
      httpVersion: '',
      method: '',
      headers: {},
      headersMap: new Map(),
      raw,
      ctx: {},
      invalid: true,
    });
    /* -------- empty buffer guard -------- */
    if (raw.length === 0) return earlyReturn();
    const [head = '', bodyString = ''] = raw.split('\r\n\r\n');
    const lines = head.split('\r\n');
    const [requestLine, ...headerLines] = lines;
    const parts = requestLine.split(' ');
    if (parts.length < 3) return earlyReturn();
    const [method, fullPath, httpVersion] = parts;
    const isOptionsStar = method === 'OPTIONS' && fullPath === '*';
    let invalid =
      !ALLOWED_METHODS.includes(method as (typeof ALLOWED_METHODS)[number]) ||
      (!fullPath.startsWith('/') && !isOptionsStar) ||
      !httpVersion.startsWith('HTTP/');
    const url = isOptionsStar
      ? new URL('http://placeholder')
      : new URL(fullPath, 'http://placeholder');
    const query: Record<string, string> = {};
    url.searchParams.forEach((v, k) => (query[k] = v));
    const headers: Record<string, string> = {};
    const headersMap = new Map<string, string[]>();
    if (headerLines.length > MAX_HEADERS) invalid = true;
    for (const line of headerLines) {
      const idx = line.indexOf(':');
      if (idx === -1) {
        invalid = true;
        continue;
      }
      const key = line.slice(0, idx).trim();
      const value = line.slice(idx + 1).trim();
      headers[key.toLowerCase()] = value;
      addHeader(headersMap, key, value);
    }
    const body = bodyString ? Buffer.from(bodyString, 'utf-8') : undefined;
    return {
      url,
      path: isOptionsStar ? '*' : decodeURIComponent(url.pathname),
      query,
      httpVersion,
      method,
      headers,
      headersMap,
      body,
      raw,
      ctx: {},
      invalid,
    };
  },
};
</file>

<file path="core/router.ts">
import { Socket } from 'net';
import { IncomingRequest } from '../entities/http';
import { sendResponse } from '../entities/sendResponse';
import { Logger, ConsoleTransport, FileTransport, PrettyFormatter } from '../utils/logger';
import path from 'path';
import { config } from '../config/server.config';
const logger = new Logger({
  transports: [
    new ConsoleTransport({
      formatter: new PrettyFormatter(),
      level: 'info',
    }),
    new FileTransport({
      filename: path.join(
        (config.logging && config.logging.logDir) || path.join(process.cwd(), 'logs'),
        'router.log',
      ),
      formatter: new PrettyFormatter(),
      level: 'debug',
    }),
  ],
  level: 'info',
  exitOnError: false,
});
export type Handler = (req: IncomingRequest, sock: Socket) => Promise<void> | void;
export type Middleware = (
  req: IncomingRequest,
  sock: Socket,
  next: () => Promise<void>,
) => Promise<void> | void;
interface Route {
  method: string;
  regex: RegExp;
  keys: string[];
  handler: Handler;
}
class Router {
  private middlewares: Middleware[] = [];
  private routes: Route[] = [];
  use(mw: Middleware) {
    this.middlewares.push(mw);
  }
  add(method: string, path: string, handler: Handler) {
    const { regex, keys } = compilePath(path);
    this.routes.push({ method: method.toUpperCase(), regex, keys, handler });
  }
  get(path: string, h: Handler) {
    this.add('GET', path, h);
  }
  post(path: string, h: Handler) {
    this.add('POST', path, h);
  }
  put(path: string, h: Handler) {
    this.add('PUT', path, h);
  }
  del(path: string, h: Handler) {
    this.add('DELETE', path, h);
  }
  any(path: string, h: Handler) {
    this.add('ANY', path, h);
  }
  async handle(req: IncomingRequest, sock: Socket): Promise<void> {
    if (req.method === 'OPTIONS') {
      sendResponse(
        sock,
        200,
        { 'Content-Type': 'text/plain', Allow: 'GET, POST, PUT, DELETE, OPTIONS' },
        'OK',
      );
      return;
    }
    if (!req.path || typeof req.path !== 'string') {
      sendResponse(
        sock,
        400,
        {
          'Content-Type':
            req.path && req.path.startsWith('/api/') ? 'application/json' : 'text/plain',
        },
        req.path && req.path.startsWith('/api/')
          ? JSON.stringify({ error: 'Bad Request' })
          : 'Bad Request',
      );
      return;
    }
    logger.info(`router saw ${req.method} ${req.path}`);
    let i = 0;
    const run = async (): Promise<void> => {
      if (i < this.middlewares.length) {
        const idx = i++;
        await this.middlewares[idx](req, sock, run);
        return;
      }
      const matching = this.routes.filter((r) => r.regex.test(req.path));
      const route =
        matching.find((r) => r.method === req.method) ?? matching.find((r) => r.method === 'ANY');
      if (!route) {
        if (matching.length) {
          const allowed = matching
            .map((r) => r.method)
            .filter((m) => m !== 'ANY')
            .join(', ');
          if (req.path.startsWith('/api/')) {
            sendResponse(
              sock,
              405,
              {
                'Content-Type': 'application/json',
                Allow: allowed,
              },
              JSON.stringify({ error: 'Method Not Allowed' }),
            );
          } else {
            sendResponse(sock, 405, { Allow: allowed }, 'Method Not Allowed');
          }
        } else {
          if (req.path.startsWith('/api/')) {
            sendResponse(
              sock,
              404,
              { 'Content-Type': 'application/json' },
              JSON.stringify({ error: 'Not Found' }),
            );
          } else {
            sendResponse(sock, 404, { 'Content-Type': 'text/plain' }, 'Not Found');
          }
        }
        return;
      }
      const match = route.regex.exec(req.path)!;
      const params: Record<string, string> = {};
      route.keys.forEach((k, idx) => {
        params[k] = decodeURIComponent(match[idx + 1]);
      });
      (req.ctx ??= {}).params = params;
      try {
        await route.handler(req, sock);
      } catch (err) {
        logger.error(`Handler error: ${(err as Error).message}`);
        if (req.path.startsWith('/api/')) {
          sendResponse(
            sock,
            500,
            { 'Content-Type': 'application/json' },
            JSON.stringify({ error: 'Internal Server Error' }),
          );
        } else {
          sendResponse(sock, 500, { 'Content-Type': 'text/plain' }, '500 Server Error');
        }
      }
    };
    try {
      await run();
    } catch (err) {
      if (req.path.startsWith('/api/')) {
        sendResponse(
          sock,
          500,
          { 'Content-Type': 'application/json' },
          JSON.stringify({ error: 'Internal Server Error' }),
        );
      } else {
        sendResponse(sock, 500, { 'Content-Type': 'text/plain' }, '500 Server Error');
      }
      logger.error(`Middleware error: ${(err as Error).message}`);
      return;
    }
  }
}
</file>

<file path="core/server.ts">
import { createServer, Socket } from 'net';
import { HttpRequestParser } from './httpParser';
import router from './router';
import logger from '../utils/logger';
import { sendResponse } from '../entities/sendResponse';
import { config } from '../config/server.config';
export class HttpServer {
  private server = createServer();
  private readonly connections = new Set<Socket>();
  private readonly router;
  constructor(
    private port: number,
    routerInstance = router,
  ) {
    this.router = routerInstance;
    this.setupServer();
  }
  private setupServer() {
    this.server.on('connection', (socket: Socket) => {
      this.connections.add(socket);
      const parser = new HttpRequestParser();
      const HEADER_TIMEOUT_MS = config.headerTimeoutMs;
      const BODY_TIMEOUT_MS = config.bodyTimeoutMs;
      let headerTimer: NodeJS.Timeout | undefined;
      let bodyTimer: NodeJS.Timeout | undefined;
      const refreshTimeout = () => {
        if (headerTimer) clearTimeout(headerTimer);
        headerTimer = setTimeout(() => {
          logger.warn('Closing idle socket (header timeout)');
          socket.destroy();
        }, HEADER_TIMEOUT_MS);
      };
      const refreshBodyTimeout = () => {
        if (bodyTimer) clearTimeout(bodyTimer);
        bodyTimer = setTimeout(() => {
          logger.warn('Closing idle socket (body timeout)');
          socket.destroy();
        }, BODY_TIMEOUT_MS);
      };
      refreshTimeout();
      socket.once('close', () => {
        this.connections.delete(socket);
        if (headerTimer) clearTimeout(headerTimer);
        if (bodyTimer) clearTimeout(bodyTimer);
      });
      logger.info('New connection established.');
      socket.on('data', async (chunk: Buffer) => {
        refreshTimeout();
        try {
          let req = parser.feed(chunk);
          if (!req) return;
          clearTimeout(headerTimer);
          do {
            if (req.method === 'POST' || req.method === 'PUT' || req.method === 'PATCH') {
              refreshBodyTimeout();
            }
            await this.router.handle(req, socket);
            clearTimeout(bodyTimer);
            req = parser.feed(Buffer.alloc(0));
          } while (req);
          const pending = parser.getPendingBytes();
          if (pending > 0) {
            refreshTimeout();
          } else {
            socket.end();
          }
        } catch (err) {
          logger.error(`Failed request: ${(err as Error).message}`);
          sendResponse(socket, 400, { 'Content-Type': 'text/plain' }, 'Bad Request');
        }
      });
      socket.on('error', (err) => {
        logger.error(`Socket error: ${err.message}`);
      });
    });
    this.server.on('error', (err: NodeJS.ErrnoException) => {
      logger.error(`Server error:`, [err, err.code, err.message]);
    });
  }
  public async stop(): Promise<void> {
    logger.info('🛑  Shutting down HTTP server');
    for (const sock of this.connections) sock.destroy();
    await new Promise<void>((resolve, reject) =>
      this.server.close((err) => (err ? reject(err) : resolve())),
    );
  }
  public destroySockets(): void {
    this.connections.forEach((socket) => socket.destroy());
  }
  public start() {
    this.server.listen(this.port, () => {
      logger.info(`🚀 Server running at port ${this.port}`);
    });
    ['SIGINT', 'SIGTERM'].forEach((sig) =>
      process.on(sig as NodeJS.Signals, () => {
        this.stop()
          .then(() => process.exit(0))
          .catch(() => process.exit(1));
      }),
    );
    ['SIGUSR2'].forEach((sig) =>
      process.once(sig as NodeJS.Signals, () => {
        this.stop().then(() => process.kill(process.pid, sig));
      }),
    );
  }
}
</file>

<file path="entities/http.ts">
export interface IncomingRequest {
  url: URL;
  path: string;
  query: Record<string, string>;
  httpVersion: string;
  method: string;
  headers: Record<string, string>;
  headersMap?: Map<string, string[]>;
  body?: Buffer;
  raw: string;
  ctx?: Record<string, unknown>;
  invalid?: boolean;
}
</file>

<file path="entities/sendResponse.ts">
import { Socket } from 'net';
import { Readable } from 'stream';
const STATUS_TEXT: Record<number, string> = {
  200: 'OK',
  206: 'Partial Content',
  400: 'Bad Request',
  404: 'Not Found',
  405: 'Method Not Allowed',
  416: 'Range Not Satisfiable',
  500: 'Internal Server Error',
};
export function sendResponse(
  socket: Socket,
  status: number,
  headers: Record<string, string>,
  body?: string | Buffer | Readable,
): void {
  const head =
    `HTTP/1.1 ${status} ${STATUS_TEXT[status] ?? ''}\r\n` +
    Object.entries(headers)
      .map(([k, v]) => `${k}: ${v}`)
      .join('\r\n') +
    '\r\n\r\n';
  socket.write(head);
  if (!body) {
    return;
  }
  if (body instanceof Readable) {
    console.log('[DEBUG] sendResponse: piping stream');
    body.once('error', (err) => {
      console.error('[DEBUG] sendResponse: stream error caught', err.message);
      if (!socket.destroyed) socket.destroy();
    });
    body.pipe(socket, { end: false });
    return;
  }
  socket.write(body);
}
</file>

<file path="modules/app-metrics/app_gallery-generator/index.ts">
export * from './metricsController';
export * from './metricsService';
</file>

<file path="modules/app-metrics/app_gallery-generator/metricsController.ts">
import { IncomingRequest } from '../../../entities/http';
import { sendResponse } from '../../../entities/sendResponse';
import { Socket } from 'net';
import { saveMetrics, isPerfLogArray } from './metricsService';
import logger from '../../../utils/logger';
export const metricsController = {
  handleMetrics: async (req: IncomingRequest, sock: Socket) => {
    try {
      if (req.method !== 'POST') {
        sendResponse(
          sock,
          405,
          {
            'Content-Type': 'text/plain',
          },
          'Method Not Allowed',
        );
        return;
      }
      let payload: unknown;
      try {
        if (Buffer.isBuffer(req.body)) {
          payload = JSON.parse(req.body.toString('utf8'));
        } else if (typeof req.body === 'string') {
          payload = JSON.parse(req.body);
        } else if (typeof req.body === 'object' && req.body !== null) {
          payload = req.body;
        } else {
          payload = {};
        }
      } catch (err) {
        logger.info(`[metrics] Invalid JSON: ${err}`);
        sendResponse(
          sock,
          400,
          { 'Content-Type': 'application/json' },
          JSON.stringify({ error: 'Invalid JSON', details: String(err) }),
        );
        return;
      }
      const clientSessionId = req.headers['x-session-id'] || req.headers['X-Session-Id'];
      if (Array.isArray(payload) && isPerfLogArray(payload)) {
        await saveMetrics(payload, clientSessionId);
        sendResponse(
          sock,
          200,
          { 'Content-Type': 'application/json' },
          JSON.stringify({ status: 'OK', payload: payload, message: 'valid payload' }),
        );
        return;
      }
      await saveMetrics(payload, clientSessionId);
      sendResponse(
        sock,
        200,
        { 'Content-Type': 'application/json' },
        JSON.stringify({ status: 'OK', payload: payload, message: 'possible invalid payload' }),
      );
    } catch (err) {
      logger.info(`[metrics] error saving payload: ${err}`);
      sendResponse(
        sock,
        500,
        {
          'Content-Type': 'text/plain',
        },
        Buffer.from(JSON.stringify({ message: 'Internal Server Error', error: err })),
      );
    }
  },
};
</file>

<file path="modules/app-metrics/app_gallery-generator/metricsService.ts">
import { z } from 'zod';
import sqlite3 from 'sqlite3';
import { open, Database } from 'sqlite';
import { config } from '../../../config/server.config';
import { Logger, FileTransport, ConsoleTransport, PrettyFormatter } from '../../../utils/logger';
import fs from 'fs';
import path from 'path';
const logger = new Logger({
  transports: [
    new ConsoleTransport({
      formatter: new PrettyFormatter(),
      level: 'info',
    }),
    new FileTransport({
      filename:
        '/Users/toluadegbehingbe/my-central-hub/src/modules/app-metrics/app_gallery-generator/._metricsService.log',
      formatter: new PrettyFormatter(),
      level: 'debug',
    }),
  ],
});
const PerfLogEntrySchema = z
  .object({
    timestamp: z.string(),
    perfNow: z.number(),
    memory: z
      .object({
        usedJSHeapSize: z.number().optional(),
        totalJSHeapSize: z.number().optional(),
        jsHeapSizeLimit: z.number().optional(),
      })
      .optional()
      .nullable(),
    action: z.string(),
    sessionId: z.string().optional(),
    batchId: z.number().optional(),
    uploadMode: z.string().optional(),
  })
  .catchall(z.unknown());
const EngagementStatsSchema = z.object({
  views: z.number(),
  lastViewedAt: z.number(),
  totalWatchMs: z.number(),
  completions: z.number(),
});
const EngagementMapSchema = z.record(EngagementStatsSchema);
const DebugLogSchema = z.object({
  message: z.string(),
  timestamp: z.string(),
});
const DebugLogsSchema = z.array(DebugLogSchema);
const SessionMetricsSchema = z.object({
  sessionId: z.string(),
  startTime: z.number(),
  firstClickTime: z.number().optional(),
  scrollDistance: z.number(),
  itemsLoaded: z.number(),
  infiniteScrollLoads: z.number(),
  hoverThumbnails: z.number(),
  gridClickOpenCount: z.number(),
  modalsOpened: z.number(),
  modalTotalTime: z.number(),
  carouselNavigationCount: z.number(),
  modalContentCounts: z.object({
    video: z.number(),
    image: z.number(),
  }),
  videoMetrics: z.object({
    plays: z.number(),
    completions: z.number(),
    watchTime: z.number(),
    manualStarts: z.number(),
    autoPlays: z.number(),
  }),
  performanceMetrics: z.object({
    preloadDurations: z.array(z.number()),
    longTasks: z.number(),
    infiniteLoadTimes: z.array(z.number()),
    modalAnimationLatencies: z.array(z.number()),
  }),
});
const FullPayloadSchema = z
  .object({
    engagement: EngagementMapSchema,
    perfLog: z.array(PerfLogEntrySchema),
    debug: DebugLogsSchema,
    timestamp: z.string(),
    sessionStart: z.number(),
    sessionMetrics: SessionMetricsSchema,
  })
  .catchall(z.unknown());
export type PerfLogEntry = z.infer<typeof PerfLogEntrySchema>;
export type FullPayload = z.infer<typeof FullPayloadSchema>;
export const metricsPayloadSchema = FullPayloadSchema;
export function isPerfLogArray(arr: unknown): arr is PerfLogEntry[] {
  return Array.isArray(arr) && arr.every((item) => PerfLogEntrySchema.safeParse(item).success);
}
let db: Database | null = null;
export async function initDb(): Promise<Database> {
  if (db) return db;
  const dbDir = path.dirname(config.dbPath);
  if (!fs.existsSync(dbDir)) {
    fs.mkdirSync(dbDir, { recursive: true });
    logger.info(`Created database directory at ${dbDir}`);
  }
  if (!fs.existsSync(config.dbPath)) {
    fs.closeSync(fs.openSync(config.dbPath, 'w'));
    logger.info(`Created new SQLite database file at ${config.dbPath}`);
  }
  db = await open({ filename: config.dbPath, driver: sqlite3.Database });
  await db.exec(`
    CREATE TABLE IF NOT EXISTS sessions (
      id TEXT PRIMARY KEY,
      timestamp TEXT,
      sessionStart INTEGER
    );
    CREATE TABLE IF NOT EXISTS engagement (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      sessionId TEXT,
      itemId TEXT,
      views INTEGER,
      lastViewedAt INTEGER,
      totalWatchMs INTEGER,
      completions INTEGER,
      FOREIGN KEY(sessionId) REFERENCES sessions(id)
    );
    CREATE TABLE IF NOT EXISTS perfLog (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      sessionId TEXT,
      timestamp TEXT,
      perfNow REAL,
      usedJSHeapSize INTEGER,
      totalJSHeapSize INTEGER,
      jsHeapSizeLimit INTEGER,
      action TEXT,
      batchId INTEGER,
      uploadMode TEXT,
      details TEXT,
      FOREIGN KEY(sessionId) REFERENCES sessions(id)
    );
    CREATE TABLE IF NOT EXISTS debug (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      sessionId TEXT,
      message TEXT,
      timestamp TEXT,
      FOREIGN KEY(sessionId) REFERENCES sessions(id)
    );
    CREATE TABLE IF NOT EXISTS sessionMetrics (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      sessionId TEXT,
      data TEXT,
      FOREIGN KEY(sessionId) REFERENCES sessions(id)
    );
  `);
  return db;
}
function logInvalid(type: string, data: unknown, error: unknown) {
  logger.info(
    `[metrics] Invalid ${type}: ${JSON.stringify(error)} | Data: ${JSON.stringify(data)}`,
  );
}
async function ensureSessionExists(
  database: Database,
  sessionId: string,
  timestamp?: string,
  sessionStart?: number,
) {
  const sessionRow = await database.get('SELECT id FROM sessions WHERE id = ?', sessionId);
  if (!sessionRow) {
    await database.run(
      'INSERT INTO sessions (id, timestamp, sessionStart) VALUES (?, ?, ?)',
      sessionId,
      timestamp || new Date().toISOString(),
      sessionStart ?? null,
    );
    logger.info(`[metrics] Created minimal session for id=${sessionId}`);
  }
}
export async function saveMetrics(
  payload: unknown,
  clientSessionId?: string,
  _env?: unknown,
) {
  const database = await initDb();
  if (Array.isArray(payload)) {
    for (const entry of payload) {
      const result = PerfLogEntrySchema.safeParse(entry);
      if (!result.success) {
        logInvalid('perfLog', entry, result.error.format());
        continue;
      }
      const resolvedSessionId = result.data.sessionId || clientSessionId;
      if (!resolvedSessionId) {
        logger.warn('[metrics] No sessionId found for perfLog entry. Skipping.');
        continue;
      }
      await ensureSessionExists(database, resolvedSessionId, result.data.timestamp);
      const { timestamp, perfNow, memory, action, batchId, uploadMode, ...rest } = result.data;
      const details = JSON.stringify({ ...rest });
      await database.run(
        `INSERT INTO perfLog (sessionId, timestamp, perfNow, usedJSHeapSize, totalJSHeapSize, jsHeapSizeLimit, action, batchId, uploadMode, details)
         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`,
        resolvedSessionId,
        timestamp,
        perfNow,
        memory?.usedJSHeapSize ?? -1,
        memory?.totalJSHeapSize ?? -1,
        memory?.jsHeapSizeLimit ?? -1,
        action,
        batchId ?? null,
        uploadMode ?? null,
        details,
      );
    }
    return;
  }
  const result = FullPayloadSchema.safeParse(payload);
  if (!result.success) {
    logInvalid('fullPayload', payload, result.error.format());
    if (payload && typeof payload === 'object') {
      const perfLogArray = Array.isArray((payload as Record<string, unknown>).perfLog)
        ? ((payload as Record<string, unknown>).perfLog as unknown[])
        : [];
      for (const entry of perfLogArray) {
        const perfResult = PerfLogEntrySchema.safeParse(entry);
        if (perfResult.success) {
          const { timestamp, perfNow, memory, action, batchId, uploadMode, ...rest } =
            perfResult.data;
          const details = JSON.stringify({ ...rest });
          await database.run(
            `INSERT INTO perfLog (sessionId, timestamp, perfNow, usedJSHeapSize, totalJSHeapSize, jsHeapSizeLimit, action, batchId, uploadMode, details)
             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`,
            null,
            timestamp,
            perfNow,
            memory?.usedJSHeapSize ?? -1,
            memory?.totalJSHeapSize ?? -1,
            memory?.jsHeapSizeLimit ?? -1,
            action,
            batchId ?? null,
            uploadMode ?? null,
            details,
          );
        } else {
          logInvalid('perfLog', entry, perfResult.error.format());
        }
      }
      const debugArray = Array.isArray((payload as Record<string, unknown>).debug)
        ? ((payload as Record<string, unknown>).debug as unknown[])
        : [];
      for (const entry of debugArray) {
        const debugResult = DebugLogSchema.safeParse(entry);
        if (debugResult.success) {
          await database.run(
            `INSERT INTO debug (sessionId, message, timestamp) VALUES (?, ?, ?)`,
            null,
            debugResult.data.message,
            debugResult.data.timestamp,
          );
        } else {
          logInvalid('debug', entry, debugResult.error.format());
        }
      }
      const engagementObj = (payload as Record<string, unknown>).engagement;
      if (engagementObj && typeof engagementObj === 'object' && !Array.isArray(engagementObj)) {
        for (const [itemId, stats] of Object.entries(engagementObj)) {
          const statsResult = EngagementStatsSchema.safeParse(stats);
          if (statsResult.success) {
            await database.run(
              `INSERT INTO engagement (sessionId, itemId, views, lastViewedAt, totalWatchMs, completions) VALUES (?, ?, ?, ?, ?, ?)`,
              null,
              itemId,
              statsResult.data.views,
              statsResult.data.lastViewedAt,
              statsResult.data.totalWatchMs,
              statsResult.data.completions,
            );
          } else {
            logInvalid('engagement', stats, statsResult.error.format());
          }
        }
      }
    }
    return;
  }
  const {
    engagement,
    perfLog,
    debug,
    timestamp,
    sessionStart,
    sessionMetrics: sessionMetricsFromPayload,
  } = result.data;
  const resolvedSessionId = sessionMetricsFromPayload.sessionId || clientSessionId;
  await ensureSessionExists(
    database,
    resolvedSessionId || 'unknown-session',
    timestamp,
    sessionStart,
  );
  for (const [itemId, stats] of Object.entries(engagement)) {
    await database.run(
      `INSERT INTO engagement (sessionId, itemId, views, lastViewedAt, totalWatchMs, completions) VALUES (?, ?, ?, ?, ?, ?)`,
      resolvedSessionId,
      itemId,
      stats.views,
      stats.lastViewedAt,
      stats.totalWatchMs,
      stats.completions,
    );
  }
  for (const entry of perfLog) {
    const { timestamp, perfNow, memory, action, batchId, uploadMode, ...rest } = entry;
    const details = JSON.stringify({ ...rest });
    await database.run(
      `INSERT INTO perfLog (sessionId, timestamp, perfNow, usedJSHeapSize, totalJSHeapSize, jsHeapSizeLimit, action, batchId, uploadMode, details) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`,
      resolvedSessionId,
      timestamp,
      perfNow,
      memory?.usedJSHeapSize ?? -1,
      memory?.totalJSHeapSize ?? -1,
      memory?.jsHeapSizeLimit ?? -1,
      action,
      batchId ?? null,
      uploadMode ?? null,
      details,
    );
  }
  for (const entry of debug) {
    await database.run(
      `INSERT INTO debug (sessionId, message, timestamp) VALUES (?, ?, ?)`,
      resolvedSessionId,
      entry.message,
      entry.timestamp,
    );
  }
  await database.run(
    `INSERT INTO sessionMetrics (sessionId, data) VALUES (?, ?)`,
    resolvedSessionId,
    JSON.stringify(sessionMetricsFromPayload),
  );
}
process.on('SIGINT', async () => {
  if (db) await db.close();
  logger.info('SQLite connection closed (SIGINT)');
  process.exit(0);
});
process.on('SIGTERM', async () => {
  if (db) await db.close();
  logger.info('SQLite connection closed (SIGTERM)');
  process.exit(0);
});
</file>

<file path="modules/app-metrics/index.ts">
export * as appGalleryGenerator from './app_gallery-generator';
</file>

<file path="modules/app-metrics/README.md">
# App Metrics Module

This module provides a structure for collecting and exposing metrics for different applications within the Central Hub project.

## Structure

- Each app has its own subfolder under `app-metrics/` (e.g., `app_gallery-generator/`).
- Each subfolder contains its own controller, service, and index.ts for modularity.
- The main `index.ts` re-exports all app metrics modules.

## Adding Metrics for a New App

1. **Create a new folder:**
   - Example: `src/modules/app-metrics/my_new_app/`
2. **Add your controller and service:**
   - `metricsController.ts` and `metricsService.ts`
3. **Export from `index.ts`:**
   - `export * from './metricsController';`
   - `export * from './metricsService';`
4. **Register the endpoint:**

   - In `src/routes/metrics.routes.ts`, add:

     ```typescript
     import { myNewAppMetricsController } from '../modules/app-metrics/my_new_app/metricsController';
     if (config.features.metrics) {
       router.post('/api/metrics/my-new-app', myNewAppMetricsController.handleMetrics);
     }
     ```

## Feature Toggling

- Metrics endpoints are only registered if `config.features.metrics` is enabled in `src/config/server.config.ts`.
- To disable all metrics endpoints, set `metrics: false` in the config.

## Example Folder Structure

```
src/modules/app-metrics/
  app_gallery-generator/
    metricsController.ts
    metricsService.ts
    index.ts
  my_new_app/
    metricsController.ts
    metricsService.ts
    index.ts
  index.ts
  README.md
```

## Best Practices

- Use RESTful route patterns: `/api/metrics/:app`.
- Keep each app’s metrics logic isolated in its own folder.
- Document new endpoints in the main README and provide usage examples.
</file>

<file path="modules/embeddings/embedding.service.ts">
import { spawn, ChildProcessWithoutNullStreams, execFile, execSync } from 'child_process';
import Ajv, { ValidateFunction } from 'ajv';
import addFormats from 'ajv-formats';
import clipCacheSchema from '../../../schemas/clipCache.schema.json';
import path from 'path';
import fs from 'fs/promises';
import { promisify } from 'util';
import { imageSize } from 'image-size';
import {
  Logger,
  ConsoleTransport,
  FileTransport,
  JsonFormatter,
  PrettyFormatter,
} from '../../utils/logger';
import { config } from '../../config/server.config';
export interface ClipCacheEntry {
  schemaVersion: string;
  filePath: string;
  mediaType: 'image' | 'video';
  mtime: number;
  fileSize: number;
  dimensions: { width: number; height: number };
  duration: number | null;
  embedding: number[];
  embeddingModel: string;
  embeddingConfig: {
    numFrames?: number | null;
    augmentation?: boolean;
    samplingMethod?: string;
    [k: string]: unknown;
  };
  processingTimestamp: string;
  debugMetadata?: { [k: string]: unknown };
  error?: string;
  detail?: string;
}
export type ClipCache = Record<string, ClipCacheEntry>;
const ajv = new Ajv({ allErrors: true });
addFormats(ajv);
let validateEntry: ValidateFunction<ClipCacheEntry>;
try {
  if (!clipCacheSchema.definitions || !(clipCacheSchema.definitions as any).ClipCacheEntry) {
    throw new Error(
      'Schema definitions or ClipCacheEntry definition missing in clipCache.schema.json',
    );
  }
  validateEntry = ajv.compile<ClipCacheEntry>((clipCacheSchema.definitions as any).ClipCacheEntry);
} catch (err: any) {
  console.error('FATAL: Failed to compile ClipCacheEntry JSON Schema:', err);
  validateEntry = ((data: any) => {
    (validateEntry as any).errors = [{ message: 'Schema compilation failed' }];
    return false;
  }) as ValidateFunction<ClipCacheEntry>;
}
const NODE_LOG_PREFIX = '[NodeEmbeddingService]';
const LOG_FILE_PATH = path.resolve(
  config.logging.logDir,
  'embedding_service.log',
);
try {
  fs.mkdir(path.dirname(LOG_FILE_PATH), { recursive: true });
} catch (e) {
  console.error('Error creating log directory:', e);
}
const logger = new Logger({
  transports: [
    new ConsoleTransport({
      formatter: new PrettyFormatter({
        useColors: true,
        useBoxes: true,
        showTimestamp: true,
      }),
      level: config.logging.level || 'info',
    }),
    new FileTransport({
      filename: LOG_FILE_PATH,
      formatter: new JsonFormatter(),
      level: 'debug',
    }),
  ],
});
const FAILED_VALIDATION_LOG_PATH = path.resolve(config.logging.logDir, 'failed_validation.log');
const failedValidationLogger = new Logger({
  transports: [
    new FileTransport({
      filename: FAILED_VALIDATION_LOG_PATH,
      formatter: new JsonFormatter(),
      level: 'error',
    }),
  ],
  level: 'error',
});
const PYTHON_EXECUTABLE = config.embedding.pythonExecutable;
const PYTHON_SCRIPT_PATH = config.embedding.pythonScriptPath;
const PYTHON_MODEL_ARGS: string[] = config.embedding?.modelArgs || [];
const INACTIVITY_TIMEOUT_MS = config.embedding?.inactivityTimeoutMs || 5 * 60 * 1000;
const PYTHON_SCRIPT_TIMEOUT_MS = config.embedding?.scriptTimeoutMs || 15 * 60 * 1000;
interface EmbeddingResponseFromPython {
  embedding?: number[];
  error?: string;
  detail?: string;
  debugMetadata?: any;
}
interface FileMetadata {
  mtime: number;
  fileSize: number;
  dimensions: { width: number; height: number };
  duration: number | null;
  mediaType: 'image' | 'video';
}
interface EmbeddingRequestInternal {
  paths: string[];
  resolve: (result: ClipCache) => void;
  reject: (error: Error) => void;
  startTime: number;
  timeoutHandle?: NodeJS.Timeout;
}
export type EmbeddingServiceState = 'IDLE' | 'PROCESSING' | 'STARTING' | 'ERROR' | 'STOPPED';
export interface EmbeddingServiceStatus {
  state: EmbeddingServiceState;
  pid: number | null;
  isStarting: boolean;
  isProcessing: boolean;
  queueLength: number;
  currentBatch?: { count: number; total: number; current: string };
  lastError?: string;
}
const execFileAsync = promisify(execFile);
class EmbeddingService {
  private pythonProcess: ChildProcessWithoutNullStreams | null = null;
  private isStarting = false;
  private isStopping = false;
  private requestQueue: EmbeddingRequestInternal[] = [];
  private currentProcessing: EmbeddingRequestInternal | null = null;
  private responseBuffer = '';
  private inactivityTimer: NodeJS.Timeout | null = null;
  private lastProgress: { processed: number; total: number; current: string } | null = null;
  private lastError: string | null = null;
  constructor() {
    logger.info(`${NODE_LOG_PREFIX} Initializing Embedding Service...`);
    this.validateConfig();
    this.checkDependencies(); // Check for ffprobe on startup
    this.setupExitHandlers();
    // Do not start the Python process immediately; wait for the first request.
  }
  private validateConfig() {
    // Basic checks for essential config/paths
    if (!PYTHON_EXECUTABLE)
      logger.warn(`${NODE_LOG_PREFIX} PYTHON_EXECUTABLE not set, defaulting.`);
    try {
      fs.access(PYTHON_SCRIPT_PATH, fs.constants.R_OK); // Check if script is readable
    } catch (e) {
      logger.error(
        `${NODE_LOG_PREFIX} Python script not found or not readable at: ${PYTHON_SCRIPT_PATH}`,
      );
      this.lastError = `Python script not accessible at ${PYTHON_SCRIPT_PATH}`;
      // Consider preventing service start if script is missing
    }
  }
  private checkDependencies() {
    // Check for ffprobe
    try {
      execSync('ffprobe -version', { stdio: 'ignore' });
      logger.info(`${NODE_LOG_PREFIX} Dependency check: ffprobe found.`);
    } catch (error) {
      logger.error(
        `${NODE_LOG_PREFIX} Dependency check failed: ffprobe not found in PATH. Video metadata extraction will fail.`,
      );
    }
  }
  private resetInactivityTimer() {
    this.clearInactivityTimer();
    if (this.pythonProcess && !this.isStopping) {
      this.inactivityTimer = setTimeout(() => {
        this.stopDueToInactivity();
      }, INACTIVITY_TIMEOUT_MS);
      if (this.inactivityTimer.unref) this.inactivityTimer.unref();
    }
  }
  private clearInactivityTimer() {
    if (this.inactivityTimer) {
      clearTimeout(this.inactivityTimer);
      this.inactivityTimer = null;
    }
  }
  private stopDueToInactivity() {
    if (this.isStopping) return;
    logger.info(`${NODE_LOG_PREFIX} Stopping Python process due to inactivity.`);
    this.isStopping = true;
    this.stop();
  }
  private async startPythonProcess(): Promise<void> {
    if (this.pythonProcess || this.isStarting) {
      logger.warn(`${NODE_LOG_PREFIX} Process already running or starting.`);
      return Promise.resolve();
    }
    if (this.lastError === `Python script not accessible at ${PYTHON_SCRIPT_PATH}`) {
      logger.error(`${NODE_LOG_PREFIX} Cannot start process, script is inaccessible.`);
      return Promise.reject(new Error(this.lastError));
    }
    this.isStarting = true;
    this.isStopping = false;
    this.lastError = null;
    logger.info(
      `${NODE_LOG_PREFIX} Starting Python process: ${PYTHON_EXECUTABLE} "${PYTHON_SCRIPT_PATH}" ${PYTHON_MODEL_ARGS.join(' ')}`,
    );
    return new Promise((resolve, reject) => {
      try {
        this.pythonProcess = spawn(PYTHON_EXECUTABLE, [PYTHON_SCRIPT_PATH, ...PYTHON_MODEL_ARGS], {
          stdio: ['pipe', 'pipe', 'pipe'],
        });
        this.isStarting = false;
        this.pythonProcess.stdout.on('data', (data: Buffer) => {
          const chunk = data.toString('utf-8');
          logger.debug(`${NODE_LOG_PREFIX} [PYTHON STDOUT RAW] ${chunk.length} chars`);
          this.responseBuffer += chunk;
          this.processResponseBuffer();
        });
        this.pythonProcess.stderr.on('data', (data: Buffer) => {
          const lines = data.toString('utf-8').split('\n');
          lines.forEach((line) => {
            const trimmed = line.trim();
            if (!trimmed) return;
            if (trimmed.startsWith('PROGRESS:')) {
              try {
                const json = trimmed.substring(9).trim();
                const progress = JSON.parse(json);
                if (progress && typeof progress === 'object') {
                  this.lastProgress = {
                    processed: Number(progress.processed) || 0,
                    total: Number(progress.total) || 0,
                    current: String(progress.current || ''),
                  };
                } else {
                  logger.warn(`${NODE_LOG_PREFIX} Invalid progress JSON structure: ${json}`);
                }
              } catch (e) {
                logger.warn(
                  `${NODE_LOG_PREFIX} Failed to parse progress line: "${trimmed}", Error: ${(e as Error).message}`,
                );
              }
            } else {
              // Log other stderr lines as errors from Python script
              logger.error(`${NODE_LOG_PREFIX} [PYTHON STDERR] ${trimmed}`);
            }
          });
        });
        this.pythonProcess.on('error', (err) => {
          logger.error(`${NODE_LOG_PREFIX} Python process spawn error: ${err.message}`);
          this.lastError = err.message;
          const startError = new Error(`Python process failed to spawn: ${err.message}`);
          this.handleProcessExit(startError);
          reject(startError);
        });
        this.pythonProcess.on('exit', (code, signal) => {
          const exitMsg = `Python process exited (Code: ${code}, Signal: ${signal})`;
          logger.warn(`${NODE_LOG_PREFIX} ${exitMsg}`);
          if (code !== 0 || signal) {
            this.lastError = exitMsg;
          }
          this.handleProcessExit(new Error(exitMsg));
        });
        logger.info(`${NODE_LOG_PREFIX} Python process started (PID: ${this.pythonProcess.pid}).`);
        this.resetInactivityTimer();
        this.processQueue();
        resolve();
      } catch (error: any) {
        logger.error(`${NODE_LOG_PREFIX} Failed to spawn Python process: ${error.message}`);
        this.isStarting = false;
        this.pythonProcess = null;
        const spawnError = new Error(`Failed to spawn Python process: ${error.message}`);
        this.lastError = spawnError.message;
        this.rejectQueue(spawnError);
        reject(spawnError);
      }
    });
  }
  private processResponseBuffer() {
    let newlineIndex;
    while ((newlineIndex = this.responseBuffer.indexOf('\n')) >= 0) {
      const jsonResponse = this.responseBuffer.substring(0, newlineIndex).trim();
      this.responseBuffer = this.responseBuffer.substring(newlineIndex + 1);
      if (jsonResponse) {
        logger.debug(
          `${NODE_LOG_PREFIX} [PYTHON RESPONSE] Processing response line (${jsonResponse.length} chars)`,
        );
        this.handlePythonJsonResponse(jsonResponse);
      }
    }
  }
  private handleProcessExit(error?: Error): void {
    const pid = this.pythonProcess?.pid;
    logger.debug(`${NODE_LOG_PREFIX} handleProcessExit called (PID: ${pid})`);
    this.pythonProcess = null;
    this.isStarting = false;
    this.clearInactivityTimer();
    if (this.currentProcessing) {
      const exitError = error || new Error('Python embedding process exited unexpectedly.');
      logger.error(
        `${NODE_LOG_PREFIX} Python process exited while processing request for ${this.currentProcessing.paths.length} paths.`,
      );
      this.currentProcessing.reject(exitError);
      if (this.currentProcessing.timeoutHandle) clearTimeout(this.currentProcessing.timeoutHandle);
      this.currentProcessing = null;
    }
    const queueError = error || new Error('Python embedding process is not available.');
    this.rejectQueue(queueError);
    if (!this.isStopping) {
      logger.info(`${NODE_LOG_PREFIX} Attempting to restart Python process in 5 seconds...`);
      setTimeout(() => {
        logger.debug(`${NODE_LOG_PREFIX} Restart timer fired.`);
        this.startPythonProcess().catch((err) => {
          logger.error(`${NODE_LOG_PREFIX} Auto-restart failed: ${err.message}`);
          this.lastError = `Auto-restart failed: ${err.message}`;
        });
      }, 5000);
    } else {
      logger.info(
        `${NODE_LOG_PREFIX} Manual stop initiated, Python process will not be restarted.`,
      );
      this.isStopping = false;
    }
  }
  private async getFileMetadata(filePath: string): Promise<FileMetadata> {
    let mtime = 0;
    let fileSize = 0;
    let dimensions = { width: 1, height: 1 };
    let duration: number | null = null;
    let mediaType: 'image' | 'video' = 'image';
    try {
      const ext = path.extname(filePath).toLowerCase();
      mediaType = ['.mp4', '.mov', '.webm', '.avi', '.mkv', '.wmv', '.m4v'].includes(ext)
        ? 'video'
        : 'image';
      const stat = await fs.stat(filePath);
      mtime = stat.mtimeMs;
      fileSize = stat.size;
      if (mediaType === 'image') {
        try {
          const buffer = Buffer.alloc(1024);
          const fd = await fs.open(filePath, 'r');
          await fd.read(buffer, 0, 1024, 0);
          await fd.close();
          const dim = imageSize(buffer);
          dimensions = { width: dim?.width ?? 1, height: dim?.height ?? 1 };
        } catch (imgErr) {
          logger.warn(
            `${NODE_LOG_PREFIX} Failed to get image dimensions for ${filePath}: ${(imgErr as Error).message}. Using default 1x1.`,
          );
        }
      } else if (mediaType === 'video') {
        try {
          const { stdout } = await execFileAsync('ffprobe', [
            '-v',
            'error',
            '-select_streams',
            'v:0',
            '-show_entries',
            'stream=width,height,duration',
            '-of',
            'json',
            filePath,
          ]);
          const info = JSON.parse(stdout);
          if (info.streams && info.streams[0]) {
            const s = info.streams[0];
            dimensions = { width: s.width ?? 1, height: s.height ?? 1 };
            duration = s.duration && !isNaN(parseFloat(s.duration)) ? parseFloat(s.duration) : null;
          } else {
            logger.warn(`${NODE_LOG_PREFIX} ffprobe found no video stream info for ${filePath}.`);
          }
        } catch (ffprobeErr) {
          logger.warn(
            `${NODE_LOG_PREFIX} ffprobe failed for ${filePath}: ${(ffprobeErr as Error).message}.`,
          );
        }
      }
    } catch (statErr) {
      logger.warn(
        `${NODE_LOG_PREFIX} Failed to stat file ${filePath}: ${(statErr as Error).message}. Using default metadata.`,
      );
    }
    return { mtime, fileSize, dimensions, duration, mediaType };
  }
  private async getBatchMetadata(filePaths: string[]): Promise<Record<string, FileMetadata>> {
    const metadataPromises = filePaths.map((fp) => this.getFileMetadata(fp));
    const results = await Promise.allSettled(metadataPromises);
    const metadataMap: Record<string, FileMetadata> = {};
    results.forEach((result, index) => {
      const filePath = filePaths[index];
      if (result.status === 'fulfilled') {
        metadataMap[filePath] = result.value;
      } else {
        logger.error(
          `${NODE_LOG_PREFIX} Failed to get metadata for ${filePath} in batch: ${result.reason?.message || result.reason}`,
        );
        metadataMap[filePath] = {
          mtime: 0,
          fileSize: 0,
          dimensions: { width: 1, height: 1 },
          duration: null,
          mediaType: path.extname(filePath).match(/\.(mp4|mov|webm)$/i) ? 'video' : 'image',
        };
      }
    });
    return metadataMap;
  }
  private async handlePythonJsonResponse(jsonResponse: string): Promise<void> {
    if (!this.currentProcessing) {
      logger.warn(`${NODE_LOG_PREFIX} Received response from Python but no request is processing.`);
      return;
    }
    const requestStartTime = this.currentProcessing.startTime;
    const currentRequest = this.currentProcessing;
    this.currentProcessing = null;
    try {
      const pythonOutput: Record<string, EmbeddingResponseFromPython> = JSON.parse(jsonResponse);
      const filePathsInResponse = Object.keys(pythonOutput);
      logger.debug(
        `${NODE_LOG_PREFIX} Parsed Python response for ${filePathsInResponse.length} files.`,
      );
      logger.debug(
        `${NODE_LOG_PREFIX} Fetching metadata for ${filePathsInResponse.length} files...`,
      );
      const batchMetadata = await this.getBatchMetadata(filePathsInResponse);
      logger.debug(`${NODE_LOG_PREFIX} Finished fetching metadata.`);
      const finalResults: ClipCache = {};
      for (const filePath of filePathsInResponse) {
        const pyEntry = pythonOutput[filePath];
        const meta = batchMetadata[filePath];
        if (!meta) {
          logger.error(
            `${NODE_LOG_PREFIX} Metadata missing for ${filePath} after batch fetch. Skipping.`,
          );
          finalResults[filePath] = {
            schemaVersion: '1.0.0',
            filePath: filePath,
            error: 'Metadata fetch failed',
            mtime: 0,
            fileSize: 0,
            dimensions: { width: 1, height: 1 },
            duration: null,
            mediaType: 'image',
            embedding: [],
            embeddingModel: 'unknown',
            embeddingConfig: {},
            processingTimestamp: new Date().toISOString(),
          } as ClipCacheEntry;
          continue;
        }
        const debug = pyEntry.debugMetadata || {};
        const embeddingModel = String(debug.model || config.embedding?.defaultModel || 'unknown');
        const embeddingConfig: ClipCacheEntry['embeddingConfig'] = {
          augmentation:
            typeof debug.enable_augmentation === 'boolean' ? debug.enable_augmentation : undefined,
          numFrames: typeof debug.num_frames === 'number' ? debug.num_frames : null,
          samplingMethod: typeof debug.method_used === 'string' ? debug.method_used : undefined,
        };
        const entryData: Partial<ClipCacheEntry> = {
          schemaVersion: '1.0.0',
          filePath: filePath,
          embedding: pyEntry.embedding,
          debugMetadata: pyEntry.debugMetadata,
          error: pyEntry.error != null ? String(pyEntry.error) : undefined,
          detail: pyEntry.detail != null ? String(pyEntry.detail) : undefined,
          processingTimestamp: new Date().toISOString(),
          mtime: meta.mtime,
          fileSize: meta.fileSize,
          dimensions: meta.dimensions,
          mediaType: meta.mediaType,
          duration: meta.duration,
          embeddingModel,
          embeddingConfig,
        };
        if (entryData.error && !entryData.embedding) {
          entryData.embedding = [];
        } else if (!entryData.embedding && !entryData.error) {
          entryData.error = 'Embedding missing without error from Python';
          entryData.embedding = [];
        }
        if (validateEntry(entryData)) {
          finalResults[filePath] = entryData as ClipCacheEntry;
        } else {
          const validationErrors = JSON.stringify(validateEntry.errors);
          logger.error(
            `${NODE_LOG_PREFIX} Constructed cache entry failed validation for: ${filePath}`,
            {
              constructedData: entryData,
              pythonData: pyEntry,
              errors: validationErrors,
            },
          );
          failedValidationLogger.error(`Failed validation for: ${filePath}`, {
            constructedData: entryData,
            pythonData: pyEntry,
            errors: validationErrors,
          });
          finalResults[filePath] = {
            schemaVersion: '1.0.0',
            filePath: filePath,
            error: 'Internal schema validation failed',
            detail: validationErrors,
            mtime: meta.mtime,
            fileSize: meta.fileSize,
            dimensions: meta.dimensions,
            duration: meta.duration,
            mediaType: meta.mediaType,
            embedding: [],
            embeddingModel: embeddingModel,
            embeddingConfig: embeddingConfig,
            processingTimestamp: entryData.processingTimestamp || new Date().toISOString(),
          } as ClipCacheEntry;
        }
      }
      const duration = Date.now() - requestStartTime;
      logger.info(
        `${NODE_LOG_PREFIX} Successfully processed batch of ${filePathsInResponse.length} paths in ${duration} ms.`,
      );
      currentRequest.resolve(finalResults);
      if (currentRequest.timeoutHandle) clearTimeout(currentRequest.timeoutHandle);
    } catch (e: any) {
      logger.error(
        `${NODE_LOG_PREFIX} Failed to parse/process JSON response from Python: ${e.message}. Response: ${jsonResponse}`,
        e,
      );
      const processingError = new Error(`Failed to process response from Python: ${e.message}`);
      currentRequest.reject(processingError);
      if (currentRequest.timeoutHandle) clearTimeout(currentRequest.timeoutHandle);
      this.lastError = processingError.message;
    } finally {
      this.processQueue();
      this.resetInactivityTimer();
    }
  }
  private rejectQueue(error: Error): void {
    if (this.requestQueue.length > 0) {
      logger.warn(
        `${NODE_LOG_PREFIX} Rejecting ${this.requestQueue.length} queued request(s) due to error: ${error.message}`,
      );
      this.requestQueue.forEach((req) => {
        if (req.timeoutHandle) clearTimeout(req.timeoutHandle);
        req.reject(error);
      });
      this.requestQueue = [];
    }
  }
  private processQueue(): void {
    if (
      this.currentProcessing ||
      this.requestQueue.length === 0 ||
      !this.pythonProcess ||
      this.isStarting
    ) {
      logger.debug(
        `${NODE_LOG_PREFIX} Skipping processQueue (Processing: ${!!this.currentProcessing}, Queue: ${this.requestQueue.length}, Proc: ${!!this.pythonProcess}, Starting: ${this.isStarting})`,
      );
      return;
    }
    this.currentProcessing = this.requestQueue.shift()!;
    this.lastProgress = null;
    logger.info(
      `${NODE_LOG_PREFIX} Sending batch of ${this.currentProcessing.paths.length} paths to Python (Queue: ${this.requestQueue.length}).`,
    );
    const requestPayload = { imagePaths: this.currentProcessing.paths };
    try {
      const requestJson = JSON.stringify(requestPayload) + '\n';
      this.responseBuffer = ''; // Clear buffer before sending new request
      // Handle potential write errors (e.g., process died between check and write)
      if (!this.pythonProcess?.stdin?.writable) {
        throw new Error('Python process stdin is not writable.');
      }
      this.pythonProcess.stdin.write(requestJson, (err) => {
        if (err) {
          logger.error(`${NODE_LOG_PREFIX} Failed to write to Python stdin: ${err.message}`);
          // Process might be dead, trigger exit handling
          const writeError = new Error(`Failed to send data to Python: ${err.message}`);
          this.currentProcessing?.reject(writeError);
          if (this.currentProcessing?.timeoutHandle)
            clearTimeout(this.currentProcessing.timeoutHandle);
          this.currentProcessing = null;
          // Don't necessarily kill here, let exit handler manage potential restart
          this.handleProcessExit(writeError);
        } else {
          logger.debug(`${NODE_LOG_PREFIX} Data written to Python stdin successfully.`);
          this.resetInactivityTimer();
        }
      });
    } catch (error: any) {
      logger.error(`${NODE_LOG_PREFIX} Error writing to Python stdin: ${error.message}`);
      const catchError = new Error(`Error sending data to Python: ${error.message}`);
      this.currentProcessing.reject(catchError);
      if (this.currentProcessing.timeoutHandle) clearTimeout(this.currentProcessing.timeoutHandle);
      this.currentProcessing = null;
      this.handleProcessExit(catchError);
    }
  }
  public async getEmbeddings(
    imagePaths: string[],
    timeoutMs = PYTHON_SCRIPT_TIMEOUT_MS,
  ): Promise<ClipCache> {
    if (!this.pythonProcess && !this.isStarting && !this.isStopping) {
      logger.info(`${NODE_LOG_PREFIX} Python process not running. Starting for new request...`);
      try {
        await this.startPythonProcess();
      } catch (startErr: any) {
        logger.error(
          `${NODE_LOG_PREFIX} Failed to start Python process for request: ${startErr.message}`,
        );
        return Promise.reject(new Error(`Failed to start Python process: ${startErr.message}`));
      }
    } else {
      this.resetInactivityTimer();
    }
    this.lastError = null;
    return new Promise((resolve, reject) => {
      let settled = false;
      const startTime = Date.now();
      const request: EmbeddingRequestInternal = {
        paths: imagePaths,
        startTime: startTime,
        resolve: (result: ClipCache) => {
          if (settled) return;
          settled = true;
          if (request.timeoutHandle) clearTimeout(request.timeoutHandle);
          this.resetInactivityTimer();
          resolve(result);
        },
        reject: (error: Error) => {
          if (settled) return;
          settled = true;
          if (request.timeoutHandle) clearTimeout(request.timeoutHandle);
          logger.error(
            `${NODE_LOG_PREFIX} Request failed after ${Date.now() - startTime} ms: ${error.message}`,
          );
          reject(error);
        },
      };
      request.timeoutHandle = setTimeout(() => {
        if (settled) return;
        logger.warn(
          `${NODE_LOG_PREFIX} Request timed out after ${timeoutMs} ms for ${imagePaths.length} paths.`,
        );
        const index = this.requestQueue.findIndex((r) => r === request);
        if (index > -1) {
          this.requestQueue.splice(index, 1);
          logger.debug(`${NODE_LOG_PREFIX} Removed timed-out request from queue.`);
        } else if (this.currentProcessing === request) {
          logger.error(
            `${NODE_LOG_PREFIX} Request timed out while actively processing. Python process might be stuck.`,
          );
          this.currentProcessing = null;
          this.lastError = `Request timed out while processing ${imagePaths.length} paths.`;
          this.stop();
        }
        request.reject(new Error(`Embedding request timed out after ${timeoutMs} ms.`));
      }, timeoutMs);
      this.requestQueue.push(request);
      logger.debug(
        `${NODE_LOG_PREFIX} Queued request for ${imagePaths.length} paths. Queue size: ${this.requestQueue.length}`,
      );
      if (!this.currentProcessing && this.pythonProcess && !this.isStarting) {
        this.processQueue();
      }
    });
  }
  public stop(): void {
    logger.info(`${NODE_LOG_PREFIX} Manual stop requested.`);
    this.isStopping = true;
    this.clearInactivityTimer();
    if (this.pythonProcess) {
      logger.info(`${NODE_LOG_PREFIX} Killing Python process (PID: ${this.pythonProcess.pid})...`);
      this.pythonProcess.kill();
      this.pythonProcess = null;
    } else {
      logger.info(`${NODE_LOG_PREFIX} Python process already stopped.`);
    }
    const stopError = new Error('Embedding service is stopping.');
    if (this.currentProcessing) {
      this.currentProcessing.reject(stopError);
      if (this.currentProcessing.timeoutHandle) clearTimeout(this.currentProcessing.timeoutHandle);
      this.currentProcessing = null;
    }
    this.rejectQueue(stopError);
  }
  public getStatus(): EmbeddingServiceStatus {
    let state: EmbeddingServiceState = 'IDLE';
    if (this.isStopping)
      state = 'STOPPED';
    else if (this.isStarting) state = 'STARTING';
    else if (!this.pythonProcess && this.lastError)
      state = 'ERROR';
    else if (!this.pythonProcess && !this.lastError)
      state = 'STOPPED';
    else if (this.currentProcessing) state = 'PROCESSING';
    const status: EmbeddingServiceStatus = {
      state,
      pid: this.pythonProcess?.pid ?? null,
      isStarting: this.isStarting,
      isProcessing: !!this.currentProcessing,
      queueLength: this.requestQueue.length,
      currentBatch: this.lastProgress
        ? {
            count: this.lastProgress.processed,
            total: this.lastProgress.total,
            current: this.lastProgress.current,
          }
        : undefined,
      lastError: this.lastError || undefined,
    };
    return status;
  }
  private setupExitHandlers() {
    const handleExit = () => {
      logger.info(`${NODE_LOG_PREFIX} Node process exiting. Stopping Python process...`);
      this.isStopping = true;
      this.stop();
    };
    process.on('exit', handleExit);
    process.on('SIGINT', () => {
      logger.info(`${NODE_LOG_PREFIX} Received SIGINT.`);
      handleExit();
      process.exit(0);
    });
    process.on('SIGTERM', () => {
      logger.info(`${NODE_LOG_PREFIX} Received SIGTERM.`);
      handleExit();
      process.exit(0);
    });
    process.on('uncaughtException', (err) => {
      logger.child([err.stack]).error(`${NODE_LOG_PREFIX} Uncaught Exception: ${err.message}`);
      handleExit();
      process.exit(1);
    });
    process.on('unhandledRejection', (reason, promise) => {
      logger.error(`${NODE_LOG_PREFIX} Unhandled Rejection at: ${promise}, reason: ${reason}`);
      handleExit();
      process.exit(1);
    });
  }
}
export const embeddingService = new EmbeddingService();
</file>

<file path="modules/embeddings/embeddings.handler.ts">
import { Socket } from 'net';
import { IncomingRequest } from '../../entities/http';
import { sendResponse } from '../../entities/sendResponse';
import {
  Logger,
  ConsoleTransport,
  FileTransport,
  JsonFormatter,
  PrettyFormatter,
} from '../../utils/logger';
import { embeddingService } from './embedding.service';
import path from 'path';
import { config } from '../../config/server.config';
const logger = new Logger({
  transports: [
    new ConsoleTransport({
      formatter: new PrettyFormatter(),
      level: 'info',
    }),
    new FileTransport({
      filename: 'logs/embeddings.log',
      formatter: new JsonFormatter(),
      level: 'debug',
    }),
  ],
  level: 'debug',
  exitOnError: false,
});
function summarizeArray(arr: any[]): string {
  if (!Array.isArray(arr)) return String(arr);
  const len = arr.length;
  if (len === 0) return '[]';
  const preview = arr.slice(0, 5).map((x) => Number(x).toFixed(4));
  let min = null,
    max = null;
  try {
    min = Math.min(...arr);
    max = Math.max(...arr);
  } catch {
  }
  return `[Array(len=${len}, min=${min}, max=${max}, preview=[${preview.join(', ')}]...)]`;
}
function summarizeObject(obj: any): any {
  if (Array.isArray(obj)) return summarizeArray(obj);
  if (obj && typeof obj === 'object') {
    const copy: any = Array.isArray(obj) ? [] : {};
    for (const key in obj) {
      if (Array.isArray(obj[key]) && obj[key].length > 20) {
        copy[key] = summarizeArray(obj[key]);
      } else if (typeof obj[key] === 'object' && obj[key] !== null) {
        copy[key] = summarizeObject(obj[key]);
      } else {
        copy[key] = obj[key];
      }
    }
    return copy;
  }
  return obj;
}
export const embeddingsController = {
  async handleEmbeddingsRequest(req: IncomingRequest, sock: Socket) {
    logger.info(
      `[EmbeddingsHandler] Received request: ` + JSON.stringify(summarizeObject(req.body)),
    );
    if (req.method !== 'POST') {
      return sendResponse(
        sock,
        405,
        { 'Content-Type': 'application/json' },
        JSON.stringify({ error: 'Method Not Allowed' }),
      );
    }
    if (!req.body || req.body.length === 0) {
      return sendResponse(
        sock,
        400,
        { 'Content-Type': 'application/json' },
        JSON.stringify({ error: 'Request body is empty' }),
      );
    }
    try {
      const body = JSON.parse(req.body.toString('utf-8'));
      const requestedPaths = body.imagePaths;
      if (!Array.isArray(requestedPaths) || requestedPaths.length === 0) {
        return sendResponse(
          sock,
          400,
          { 'Content-Type': 'application/json' },
          JSON.stringify({ error: 'No file paths provided.' }),
        );
      }
      const mediaDir = path.resolve(config.mediaDir);
      const imagePaths: string[] = [];
      for (const reqPath of requestedPaths) {
        if (typeof reqPath !== 'string') {
          logger.warn(`[EmbeddingsHandler] Invalid path type received: ${typeof reqPath}`);
          continue;
        }
        const absoluteReqPath = path.resolve(mediaDir, reqPath);
        if (!absoluteReqPath.startsWith(mediaDir) && !config.testMode) {
          logger.error(`[EmbeddingsHandler] Invalid path detected (outside media dir): ${reqPath}`);
          return sendResponse(
            sock,
            400,
            { 'Content-Type': 'application/json' },
            JSON.stringify({
              error: 'Invalid file path provided.',
              detail: `Path ${reqPath} is outside the allowed directory.`,
            }),
          );
        }
        imagePaths.push(absoluteReqPath);
      }
      if (imagePaths.length === 0) {
        logger.warn(`[EmbeddingsHandler] No valid paths remaining after validation.`);
        return sendResponse(
          sock,
          400,
          { 'Content-Type': 'application/json' },
          JSON.stringify({ error: 'No valid file paths provided.' }),
        );
      }
      logger.info(
        `[EmbeddingsHandler] Requesting embeddings for ${imagePaths.length} validated paths.`,
      );
      const embeddingsResult = await embeddingService.getEmbeddings(imagePaths);
      logger.info(
        `[EmbeddingsHandler] Sending response for ${imagePaths.length} paths. Result summary: ` +
          JSON.stringify(summarizeObject(embeddingsResult)),
      );
      sendResponse(
        sock,
        200,
        { 'Content-Type': 'application/json' },
        JSON.stringify(embeddingsResult),
      );
    } catch (error: any) {
      logger.error(`[EmbeddingsHandler] Error processing embedding request: ${error.message}`);
      logger.error(`[EmbeddingsHandler] Error detail: ` + JSON.stringify(summarizeObject(error)));
      const statusCode = error instanceof SyntaxError ? 400 : 500;
      const errorMessage =
        error instanceof SyntaxError
          ? 'Invalid JSON in request body.'
          : 'Failed to process embeddings.';
      sendResponse(
        sock,
        statusCode,
        { 'Content-Type': 'application/json' },
        JSON.stringify({ error: errorMessage, detail: error.message }),
      );
    }
  },
  async handleShutdownRequest(req: IncomingRequest, sock: Socket) {
    logger.info(`[EmbeddingsHandler] Received shutdown request`);
    if (req.method !== 'POST') {
      return sendResponse(
        sock,
        405,
        { 'Content-Type': 'application/json' },
        JSON.stringify({ error: 'Method Not Allowed' }),
      );
    }
    embeddingService.stop();
    logger.info(`[EmbeddingsHandler] Embedding service stop initiated.`);
    sendResponse(
      sock,
      200,
      { 'Content-Type': 'application/json' },
      JSON.stringify({ message: 'Embedding service shutdown initiated.' }),
    );
  },
  async handleStatusRequest(req: IncomingRequest, sock: Socket) {
    if (req.method !== 'GET') {
      return sendResponse(
        sock,
        405,
        { 'Content-Type': 'application/json' },
        JSON.stringify({ error: 'Method Not Allowed' }),
      );
    }
    const status = embeddingService.getStatus();
    sendResponse(sock, 200, { 'Content-Type': 'application/json' }, JSON.stringify(status));
  },
};
</file>

<file path="modules/file-hosting/fileHostingController.ts">
import { Socket } from 'net';
import { sendResponse } from '../../entities/sendResponse';
import { IncomingRequest } from '../../entities/http';
import { FileHostingService } from './fileHostingService';
import { getHeader, getQuery } from '../../utils/httpHelpers';
import { config } from '../../config/server.config';
import logger from '../../utils/logger';
import { getMimeType } from '../../utils/helpers';
import { Readable } from 'stream';
const fileSvc = new FileHostingService(config.mediaDir);
export const fileHostingController = {
  async getFile(req: IncomingRequest, sock: Socket) {
    logger.info(`[getFile] url=${req.url} path=${req.path} query=${JSON.stringify(req.query)}`);
    const fileName = getQuery(req, 'file');
    if (!fileName) {
      sendResponse(
        sock,
        400,
        { 'Content-Type': 'text/plain' },
        'Missing required "file" query parameter.',
      );
      return;
    }
    try {
      const rangeHdr = getHeader(req, 'range');
      let stream: Readable;
      const fileStat = await fileSvc.stat(fileName);
      const size = fileStat.size;
      if (rangeHdr) {
        const m = /bytes=(\d*)-(\d*)/.exec(rangeHdr);
        if (!m) {
          sendResponse(sock, 416, { 'Content-Type': 'text/plain' }, '416 Range Not Satisfiable');
          sock.end();
          return;
        }
        const startStr = m[1];
        const endStr = m[2];
        let start: number;
        let end: number;
        if (startStr) {
          start = parseInt(startStr, 10);
          end = endStr ? parseInt(endStr, 10) : size - 1;
        } else {
          const suffix = parseInt(endStr, 10);
          start = size - suffix;
          end = size - 1;
        }
        if (start > end || start < 0 || end >= size) {
          sendResponse(sock, 416, { 'Content-Type': 'text/plain' }, '416 Range Not Satisfiable');
          sock.end();
          return;
        }
        stream = await fileSvc.readFile(fileName, { start, end });
        if (!stream) throw new Error('Stream is undefined');
        stream.on('error', (err: Error) => {
          logger.error(`[getFile] Stream error: ${err.message}`);
          sendResponse(sock, 500, { 'Content-Type': 'text/plain' }, 'Internal Server Error');
        });
        const len = end - start + 1;
        sendResponse(
          sock,
          206,
          {
            'Content-Type': getMimeType(fileName) || 'application/octet-stream',
            'Accept-Ranges': 'bytes',
            'Content-Range': `bytes ${start}-${end}/${size}`,
            'Content-Length': String(len),
          },
          stream,
        );
      } else {
        stream = await fileSvc.readFile(fileName);
        if (!stream) throw new Error('Stream is undefined');
        stream.on('error', (err: Error) => {
          logger.error(`[getFile] Stream error: ${err.message}`);
          sendResponse(sock, 500, { 'Content-Type': 'text/plain' }, 'Internal Server Error');
        });
        const mimeType = getMimeType(fileName);
        sendResponse(
          sock,
          200,
          { 'Content-Type': mimeType, 'Content-Length': String(size) },
          stream,
        );
      }
    } catch (err: unknown) {
      logger.error(`[getFile] fileName=${fileName}, error=${(err as Error).message}`);
      sendResponse(sock, 404, { 'Content-Type': 'text/plain' }, `File "${fileName}" not found.`);
    }
  },
  async listFiles(req: IncomingRequest, sock: Socket) {
    try {
      const files = await fileSvc.listFiles();
      sendResponse(sock, 200, { 'Content-Type': 'application/json' }, JSON.stringify(files));
    } catch (err: unknown) {
      logger.error(`listFiles: ${(err as Error).message}`);
      sendResponse(sock, 500, { 'Content-Type': 'text/plain' }, 'Server error');
    }
  },
  async uploadFile(req: IncomingRequest, sock: Socket) {
    const fileName = getQuery(req, 'file') || req.headers['x-filename'];
    if (!fileName) {
      sendResponse(sock, 400, { 'Content-Type': 'text/plain' }, 'Missing file name');
      return;
    }
    const mimeType = getMimeType(fileName);
    if (
      !mimeType.startsWith('image/') &&
      !mimeType.startsWith('video/') &&
      !mimeType.startsWith('audio/')
    ) {
      sendResponse(sock, 400, { 'Content-Type': 'text/plain' }, 'Only media files allowed');
      return;
    }
    if (!req.body) {
      sendResponse(sock, 400, { 'Content-Type': 'text/plain' }, 'No file data');
      return;
    }
    const fileSvc = new FileHostingService(config.mediaDir);
    async function* bufferToAsyncIterable(buffer: Buffer) {
      yield buffer;
    }
    const data = typeof req.body === 'string' ? Buffer.from(req.body) : req.body;
    await fileSvc.saveFile(fileName, bufferToAsyncIterable(data));
    sendResponse(sock, 200, { 'Content-Type': 'text/plain' }, 'Upload successful');
  },
  async deleteFile(req: IncomingRequest, sock: Socket) {
    const fileName = getQuery(req, 'file');
    if (!fileName) {
      sendResponse(sock, 400, { 'Content-Type': 'text/plain' }, 'Missing file name');
      return;
    }
    const fileSvc = new FileHostingService(config.mediaDir);
    const absPath = fileSvc['resolveSafe'](fileName);
    try {
      await import('fs/promises').then((fs) => fs.unlink(absPath));
      sendResponse(sock, 200, { 'Content-Type': 'text/plain' }, 'File deleted');
    } catch {
      sendResponse(
        sock,
        404,
        { 'Content-Type': 'text/plain' },
        'File not found or could not be deleted',
      );
    }
  },
};
</file>

<file path="modules/file-hosting/fileHostingService.ts">
import { createReadStream, createWriteStream } from 'fs';
import { stat, readdir, mkdir } from 'fs/promises';
import { resolve } from 'path';
import { Readable } from 'stream';
export class FileHostingService {
  constructor(private readonly rootDir: string) {}
  private resolveSafe(relPath: string): string {
    const abs = resolve(this.rootDir, relPath);
    if (!abs.startsWith(this.rootDir)) throw new Error('Path traversal attempt');
    return abs;
  }
  async listFiles(relDir = '.'): Promise<string[]> {
    return await readdir(this.resolveSafe(relDir));
  }
  async stat(relPath: string) {
    return await stat(this.resolveSafe(relPath));
  }
  async readFile(relPath: string, range?: { start: number; end: number }): Promise<Readable> {
    const abs = this.resolveSafe(relPath);
    return createReadStream(abs, range);
  }
  async saveFile(relPath: string, data: AsyncIterable<Buffer>): Promise<void> {
    const abs = this.resolveSafe(relPath);
    await mkdir(resolve(abs, '..'), { recursive: true });
    const ws = createWriteStream(abs);
    for await (const chunk of data) ws.write(chunk);
    await new Promise<void>((res, rej) => {
      ws.end(res);
      ws.on('error', rej);
    });
  }
}
</file>

<file path="modules/file-hosting/index.ts">
export * from './fileHostingController';
export * from './fileHostingService';
</file>

<file path="modules/file-streaming/fileService.ts">
export class FileService {
  constructor(private readonly rootDir: string) {
    throw new Error('FileService is deprecated. Use file-hosting module instead.');
  }
}
</file>

<file path="modules/file-streaming/fileStreamingController.ts">
import { Socket } from 'net';
import { sendResponse } from '../../entities/sendResponse';
import { IncomingRequest } from '../../entities/http';
import { getHeader, getQuery } from '../../utils/httpHelpers';
import { config } from '../../config/server.config';
import { Logger } from '../../utils/logger';
const logger = new Logger();
import { getMimeType } from '../../utils/helpers';
import { Readable } from 'stream';
import { FileHostingService } from '../file-hosting/fileHostingService';
const fileSvc = new FileHostingService(config.mediaDir);
export const fileStreamingController = {
  async handleStream(req: IncomingRequest, sock: Socket) {
    if (!config.testMode) {
      logger.info(
        `[handleStream] url=${req.url} path=${req.path} query=${JSON.stringify(req.query)}`,
      );
    }
    const fileName = getQuery(req, 'file');
    if (!fileName) {
      sendResponse(
        sock,
        400,
        { 'Content-Type': 'text/plain' },
        'Missing required "file" query parameter.',
      );
      return;
    }
    try {
      const rangeHdr = getHeader(req, 'range');
      let stream: Readable;
      const fileStat = await fileSvc.stat(fileName);
      const size = fileStat.size;
      if (rangeHdr) {
        const m = /bytes=(\d*)-(\d*)/.exec(rangeHdr);
        if (!m) {
          sendResponse(sock, 416, { 'Content-Type': 'text/plain' }, '416 Range Not Satisfiable');
          sock.end();
          return;
        }
        const startStr = m[1];
        const endStr = m[2];
        let start: number;
        let end: number;
        if (startStr) {
          start = parseInt(startStr, 10);
          end = endStr ? parseInt(endStr, 10) : size - 1;
        } else {
          const suffix = parseInt(endStr, 10);
          start = size - suffix;
          end = size - 1;
        }
        if (start > end || start < 0 || end >= size) {
          sendResponse(sock, 416, { 'Content-Type': 'text/plain' }, '416 Range Not Satisfiable');
          sock.end();
          return;
        }
        stream = await fileSvc.readFile(fileName, { start, end });
        if (!stream) throw new Error('Stream is undefined');
        const len = end - start + 1;
        sendResponse(
          sock,
          206,
          {
            'Content-Type': getMimeType(fileName) || 'application/octet-stream',
            'Accept-Ranges': 'bytes',
            'Content-Range': `bytes ${start}-${end}/${size}`,
            'Content-Length': String(len),
          },
          stream,
        );
      } else {
        stream = await fileSvc.readFile(fileName);
        if (!stream) throw new Error('Stream is undefined');
        const mimeType = getMimeType(fileName);
        sendResponse(
          sock,
          200,
          { 'Content-Type': mimeType, 'Content-Length': String(size) },
          stream,
        );
      }
    } catch (err) {
      if (!config.testMode) {
        logger.error(`[handleStream] fileName=${fileName}, error=${(err as Error).message}`);
      }
      sendResponse(sock, 404, { 'Content-Type': 'text/plain' }, `File "${fileName}" not found.`);
    }
  },
};
</file>

<file path="modules/file-streaming/index.ts">
export * from './fileService';
export * from './fileStreamingController';
</file>

<file path="routes/embeddings.routes.ts">
import router from '../core/router';
import { embeddingsController } from '../modules/embeddings/embeddings.handler';
router.post('/api/embeddings', embeddingsController.handleEmbeddingsRequest);
router.post('/api/embeddings/shutdown', embeddingsController.handleShutdownRequest);
router.get('/api/embeddings/status', embeddingsController.handleStatusRequest);
</file>

<file path="routes/file-hosting.routes.ts">
import router from '../core/router';
import { fileHostingController } from '../modules/file-hosting';
router.get('/api/files', fileHostingController.listFiles);
router.post('/api/files', fileHostingController.uploadFile);
router.get('/api/files/:filename', fileHostingController.getFile);
router.del('/api/files/:filename', fileHostingController.deleteFile);
</file>

<file path="routes/files.routes.ts">
import router from '../core/router';
import { fileHostingController } from '../modules/file-hosting';
router.get('/files', fileHostingController.listFiles);
</file>

<file path="routes/index.ts">
import './stream.routes';
import './files.routes';
import './metrics.routes';
import './embeddings.routes';
import './file-hosting.routes';
import router from '../core/router';
import { sendResponse } from '../entities/sendResponse';
['/echo', '/ping'].forEach((path) =>
  router.any(path, async (req, sock) => {
    const message =
      path === '/ping'
        ? undefined
        : (() => {
            try {
              const body = req.body ? JSON.parse(req.body.toString()) : {};
              return typeof body?.message === 'string' ? body.message : 'Hello, world!';
            } catch {
              return 'Hello, world!';
            }
          })();
    const res = message ? JSON.stringify({ message }) : '';
    sendResponse(
      sock,
      200,
      { 'Content-Type': 'application/json', 'Content-Length': Buffer.byteLength(res).toString() },
      res,
    );
  }),
);
export {};
</file>

<file path="routes/metrics.routes.ts">
import router from '../core/router';
import { metricsController } from '../modules/app-metrics/app_gallery-generator';
import { config } from '../config/server.config';
import { sendResponse as sendCustomResponse } from '../entities/sendResponse';
import { Readable } from 'stream';
import { Socket } from 'net';
router.use(async (req, sock, next) => {
  if (req.path.startsWith('/api/metrics/')) {
    const headers = {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, X-Session-Id',
    };
    if (req.method === 'OPTIONS') {
      sock.write(
        [
          'HTTP/1.1 204 No Content',
          ...Object.entries(headers).map(([k, v]) => `${k}: ${v}`),
          '',
          '',
        ].join('\r\n'),
      );
      sock.end();
      return;
    } else {
      req.ctx = req.ctx || {};
      req.ctx.corsHeaders = headers;
    }
  }
  await next();
});
if (config.features.metrics) {
  router.post('/api/metrics/gallery-generator', async (req, sock) => {
    const sendCustomResponse = (
      sock: Socket,
      status: number,
      headers: Record<string, string>,
      body?: string | Buffer | Readable,
    ) => {
      const corsHeaders = req.ctx && req.ctx.corsHeaders ? req.ctx.corsHeaders : {};
      sendCustomResponse(sock, status, { ...headers, ...corsHeaders }, body);
    };
    await metricsController.handleMetrics(req, sock);
  });
}
</file>

<file path="routes/stream.routes.ts">
import router from '../core/router';
import { fileStreamingController } from '../modules/file-streaming';
import { config } from '../config/server.config';
if (config.features.fileStreaming) {
  router.get('/api/stream', fileStreamingController.handleStream);
}
</file>

<file path="utils/helpers.ts">
import { extname } from 'path';
import { mimeTypes } from './mimeTypes';
export function getMimeType(fileName: string): string {
  const ext = extname(fileName).toLowerCase();
  return mimeTypes[ext] || 'application/octet-stream';
}
</file>

<file path="utils/httpHelpers.ts">
import { IncomingRequest } from '../entities/http';
export function getHeader(req: IncomingRequest, name: string): string | undefined {
  const key = name.toLowerCase();
  if (req.headersMap && req.headersMap.has(key)) {
    return req.headersMap.get(key)![0];
  }
  return req.headers?.[key];
}
export function getQuery(req: IncomingRequest, key: string): string | undefined {
  if (req.invalid || !req.query || !req.url) return undefined;
  const direct = req.query?.[key];
  if (direct !== undefined) return direct;
  return req.url.searchParams.get(key) ?? undefined;
}
</file>

<file path="utils/logger.ts">
import fs from 'fs';
import path from 'path';
import chalk from 'chalk';
import boxen from 'boxen';
import { Writable } from 'stream';
const standardLevels = {
  error: 0,
  warn: 1,
  info: 2,
  http: 3,
  verbose: 4,
  debug: 5,
  silly: 6,
};
type LogLevel = keyof typeof standardLevels;
type CustomLevels = Record<string, number>;
type AllLogLevels = LogLevel | 'success' | keyof CustomLevels;
export interface LogEntry {
  level: string;
  message: string | object;
  meta?: Record<string, any>;
  timestamp: Date;
}
export interface Formatter {
  format(entry: LogEntry): string;
}
export interface Transport {
  log(formattedMessage: string, entry: LogEntry): void;
  level?: string;
  close?(): void;
  formatter: Formatter;
}
export class JsonFormatter implements Formatter {
  format(entry: LogEntry): string {
    const logObject = {
      level: entry.level,
      message: entry.message,
      timestamp: entry.timestamp.toISOString(),
      ...entry.meta,
    };
    try {
      return JSON.stringify(logObject, (key, value) =>
        typeof value === 'bigint' ? value.toString() : value,
      );
    } catch (error) {
      return JSON.stringify({
        level: entry.level,
        message: `[Unserializable Object: ${
          error instanceof Error ? error.message : String(error)
        }]`,
        timestamp: entry.timestamp.toISOString(),
        ...entry.meta,
      });
    }
  }
}
export class PrettyFormatter implements Formatter {
  private readonly options: {
    useColors: boolean;
    useBoxes: boolean;
    maxDepth: number;
    indent: number;
    stringLengthLimit: number;
    arrayLengthLimit: number;
    objectKeysLimit: number;
    showTimestamp: boolean;
  };
  private static LANGUAGE_COLOR_MAP: Record<string, (s: string) => string> = {
    python: chalk.magentaBright,
    typescript: chalk.cyanBright,
    javascript: chalk.yellowBright,
    shell: chalk.greenBright,
    default: chalk.whiteBright,
  };
  private static LEVEL_STYLES: Record<
    string,
    { color: (s: string) => string; icon: string; colorName: string }
  > = {
    error: { color: chalk.red, icon: '✖', colorName: 'red' },
    warn: { color: chalk.yellow, icon: '⚠', colorName: 'yellow' },
    info: { color: chalk.blueBright, icon: 'ℹ', colorName: 'blueBright' },
    success: { color: chalk.green, icon: '✔', colorName: 'green' },
    http: { color: chalk.magenta, icon: '↔', colorName: 'magenta' },
    verbose: { color: chalk.gray, icon: ' V ', colorName: 'gray' },
    debug: { color: chalk.cyan, icon: ' D ', colorName: 'cyan' },
    silly: { color: chalk.white, icon: ' S ', colorName: 'white' },
    default: { color: chalk.white, icon: ' ', colorName: 'white' },
  };
  constructor(options: Partial<PrettyFormatter['options']> = {}) {
    this.options = {
      useColors: options.useColors ?? true,
      useBoxes: options.useBoxes ?? false,
      maxDepth: options.maxDepth ?? 3,
      indent: options.indent ?? 2,
      stringLengthLimit: options.stringLengthLimit ?? 150,
      arrayLengthLimit: options.arrayLengthLimit ?? 5,
      objectKeysLimit: options.objectKeysLimit ?? 5,
      showTimestamp: options.showTimestamp ?? false,
    };
  }
  private detectLanguage(context?: string): string {
    if (!context) return 'default';
    if (context.endsWith('.py')) return 'python';
    if (context.endsWith('.ts')) return 'typescript';
    if (context.endsWith('.js')) return 'javascript';
    if (context.endsWith('.sh')) return 'shell';
    return 'default';
  }
  private highlightSemantics(str: string): string {
    if (!this.options.useColors) return str;
    try {
      const hasAnsi = new RegExp(
        '(?:\\u001b\\[[0-9;]*m|\\x1b\\[[0-9;]*m|\\u001b\\[.*?m|\\x1b\\[.*?m)',
      ).test(str);
      str = str.replace(
        /([./\w-]+\.(?:ts|js|py|sh|json|log|txt|md|html|css))/g,
        chalk.underline.blue('$1'),
      );
      str = str.replace(
        /\b(error|exception|fail(?:ed)?|traceback|stack|warn(?:ing)?|critical|fatal)\b/gi,
        chalk.bgRed.white('$1'),
      );
      if (!this.options.useBoxes && !hasAnsi) {
        str = str.replace(/\b(\d+(?:\.\d+)?)\b/g, chalk.yellow('$1'));
      }
      str = str.replace(/\b(INFO|DEBUG|WARN|ERROR|SUCCESS|HTTP|VERBOSE|SILLY)\b/g, (match) => {
        const style = PrettyFormatter.LEVEL_STYLES[match.toLowerCase()] || {
          color: chalk.white,
        };
        return style.color(match);
      });
    } catch (e) {
      console.error('PrettyFormatter highlighting error:', e);
    }
    return str;
  }
  private formatValue(value: any, level = 0): string {
    const pad = ' '.repeat(this.options.indent * level);
    const colorize = this.options.useColors;
    if (level > this.options.maxDepth) {
      if (Array.isArray(value)) return colorize ? chalk.gray('[Array]') : '[Array]';
      if (typeof value === 'object' && value !== null)
        return colorize ? chalk.gray('[Object]') : '[Object]';
      return colorize ? chalk.gray('...') : '...';
    }
    if (value === null) return colorize ? chalk.gray('null') : 'null';
    if (value === undefined) return colorize ? chalk.gray('undefined') : 'undefined';
    if (typeof value === 'string') {
      const highlighted = this.highlightSemantics(value);
      const truncated =
        highlighted.length > this.options.stringLengthLimit
          ? highlighted.slice(0, this.options.stringLengthLimit) + '...'
          : highlighted;
      const jsonStr = JSON.stringify(truncated);
      return colorize ? chalk.yellowBright(jsonStr.slice(1, -1)) : jsonStr.slice(1, -1);
    }
    if (typeof value === 'number')
      return colorize ? chalk.green(value.toString()) : value.toString();
    if (typeof value === 'boolean')
      return colorize ? chalk.magenta(value.toString()) : value.toString();
    if (typeof value === 'bigint')
      return colorize ? chalk.greenBright(value.toString() + 'n') : value.toString() + 'n';
    if (typeof value === 'function')
      return colorize ? chalk.blueBright('[Function]') : '[Function]';
    if (value instanceof Date)
      return colorize ? chalk.greenBright(value.toISOString()) : value.toISOString();
    if (value instanceof Error) {
      const stack = value.stack ? `\n${value.stack.split('\n').slice(1).join('\n')}` : ''; // Show stack excluding first line
      const formattedError = `${value.name}: ${value.message}${stack}`;
      return colorize ? chalk.redBright(this.highlightSemantics(formattedError)) : formattedError;
    }
    if (value instanceof RegExp)
      return colorize ? chalk.magentaBright(value.toString()) : value.toString();
    if (Array.isArray(value)) {
      if (value.length === 0) return '[]';
      let out = '[\n';
      const max = this.options.arrayLengthLimit;
      for (let i = 0; i < Math.min(value.length, max); i++) {
        out += pad + '  ' + this.formatValue(value[i], level + 1);
        if (i < Math.min(value.length, max) - 1 || value.length > max) out += ',';
        out += '\n';
      }
      if (value.length > max) {
        const moreText = `... ${value.length - max} more item(s)`;
        out += pad + '  ' + (colorize ? chalk.gray(moreText) : moreText) + '\n';
      }
      out += pad + ']';
      return out;
    }
    if (typeof value === 'object' && value !== null) {
      try {
        const keys = Object.keys(value);
        if (keys.length === 0) return '{}';
        let out = '{\n';
        const max = this.options.objectKeysLimit;
        for (let idx = 0; idx < Math.min(keys.length, max); idx++) {
          const key = keys[idx];
          const keyStr = colorize ? chalk.cyanBright(`"${key}"`) : `"${key}"`;
          out += pad + '  ' + keyStr + ': ';
          out += this.formatValue(value[key], level + 1);
          if (idx < Math.min(keys.length, max) - 1 || keys.length > max) out += ',';
          out += '\n';
        }
        if (keys.length > max) {
          const moreText = `... ${keys.length - max} more key(s)`;
          out += pad + '  ' + (colorize ? chalk.gray(moreText) : moreText) + '\n';
        }
        out += pad + '}';
        return out;
      } catch (e) {
        return colorize
          ? chalk.redBright('[Object Formatting Error]')
          : '[Object Formatting Error]';
      }
    }
    return colorize ? chalk.white(String(value)) : String(value);
  }
  format(entry: LogEntry): string {
    const { level, message, meta, timestamp } = entry;
    const style = PrettyFormatter.LEVEL_STYLES[level] || PrettyFormatter.LEVEL_STYLES.default;
    let formattedMessage = typeof message === 'string' ? message : JSON.stringify(message);
    let formattedMeta = '';
    if (meta && Object.keys(meta).length > 0 && meta !== message) {
      formattedMeta = typeof meta === 'string' ? meta : JSON.stringify(meta);
    }
    let combinedOutput = formattedMessage;
    if (formattedMeta && formattedMeta !== '{}') {
      combinedOutput += `\nMeta: ${formattedMeta}`;
    }
    const timestampStr = this.options.showTimestamp ? `[${timestamp.toISOString()}] ` : '';
    const levelStr = `${style.icon} ${level.toUpperCase()} `;
    let finalMessage = `${timestampStr}${levelStr}${combinedOutput}`;
    if (this.options.useBoxes && this.options.useColors) {
      // Only color the box, not the content
      return boxen(finalMessage, {
        padding: 1,
        margin: { top: 0, bottom: 1, left: 0, right: 0 },
        borderStyle: 'round',
        borderColor: style.colorName,
        backgroundColor: undefined,
        title: undefined,
        titleAlignment: 'center',
      });
    } else if (this.options.useColors) {
      return style.color(finalMessage);
    } else {
      return finalMessage;
    }
  }
}
export class ConsoleTransport implements Transport {
  public formatter: Formatter;
  public level?: string;
  constructor(options: { formatter?: Formatter; level?: string } = {}) {
    this.formatter = options.formatter ?? new PrettyFormatter({ useColors: true, useBoxes: false });
    this.level = options.level;
  }
  log(formattedMessage: string, entry: LogEntry): void {
    if (entry.level === 'error') {
      console.error(formattedMessage);
    } else if (entry.level === 'warn') {
      console.warn(formattedMessage);
    } else {
      console.log(formattedMessage);
    }
  }
}
export class FileTransport implements Transport {
  public formatter: Formatter;
  private stream: Writable;
  private filename: string;
  public level?: string;
  constructor(options: { filename: string; formatter?: Formatter; level?: string }) {
    this.filename = options.filename;
    this.formatter = options.formatter ?? new JsonFormatter();
    this.level = options.level;
    this.ensureLogDir(this.filename);
    this.stream = fs.createWriteStream(this.filename, { flags: 'a' });
    this.stream.on('error', (err) => {
      console.error(`Error writing to log file ${this.filename}:`, err);
    });
    this.stream.on('finish', () => {
    });
  }
  private ensureLogDir(logPath: string): void {
    const dir = path.dirname(logPath);
    try {
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
    } catch (err) {
      console.error(`Failed to create log directory ${dir}:`, err);
    }
  }
  log(formattedMessage: string, entry: LogEntry): void {
    this.stream.write(formattedMessage + '\n', (err) => {
      if (err) {
        console.error(`Failed to write to log stream ${this.filename}:`, err);
      }
    });
  }
  close(): void {
    new Promise<void>((resolve) => {
      this.stream.end(() => resolve());
    }).catch((err) => {
      console.error(`Error closing log stream ${this.filename}:`, err);
    });
  }
}
export interface LoggerOptions {
  level?: LogLevel | string;
  levels?: CustomLevels;
  transports?: Transport[];
  metadata?: Record<string, any>;
  exitOnError?: boolean;
}
export class Logger {
  private options: Required<Omit<LoggerOptions, 'levels'>>;
  private levels: Record<string, number>;
  private transports: Transport[];
  error!: (message: string | object, meta?: Record<string, any>) => void;
  warn!: (message: string | object, meta?: Record<string, any>) => void;
  info!: (message: string | object, meta?: Record<string, any>) => void;
  http!: (message: string | object, meta?: Record<string, any>) => void;
  verbose!: (message: string | object, meta?: Record<string, any>) => void;
  debug!: (message: string | object, meta?: Record<string, any>) => void;
  silly!: (message: string | object, meta?: Record<string, any>) => void;
  success!: (message: string | object, meta?: Record<string, any>) => void;
  constructor(options: LoggerOptions = {}) {
    this.levels = {
      ...standardLevels,
      success: standardLevels.info,
      ...(options.levels ?? {}),
    };
    const defaultTransports = options.transports ?? [
      new ConsoleTransport({
        formatter: new PrettyFormatter({ useColors: true }),
      }),
    ];
    this.options = {
      level: options.level ?? 'info',
      transports: defaultTransports,
      metadata: options.metadata ?? {},
      exitOnError: options.exitOnError ?? false,
    };
    this.transports = this.options.transports;
    Object.keys(this.levels).forEach((level) => {
      (this as any)[level] = (message: string | object, meta?: Record<string, any>) => {
        this.log(level, message, meta);
      };
    });
  }
  log(level: string, message: string | object, meta?: Record<string, any>): void {
    const levelValue = this.levels[level as string] ?? -1;
    const configuredLevelValue = this.levels[this.options.level as string] ?? this.levels.info;
    if (levelValue === -1) {
      console.warn(`Attempted to log with unknown level: "${level}"`);
      return;
    }
    if (levelValue > configuredLevelValue) {
      return;
    }
    const entry: LogEntry = {
      level,
      message,
      meta: { ...this.options.metadata, ...meta },
      timestamp: new Date(),
    };
    this.transports.forEach((transport) => {
      const transportLevel = transport.level ?? this.options.level;
      const transportLevelValue =
        this.levels[transportLevel as Exclude<keyof AllLogLevels, symbol>] ?? configuredLevelValue;
      if (typeof transportLevelValue === 'number' && levelValue <= transportLevelValue) {
        const formattedMessage = transport.formatter.format(entry);
        try {
          transport.log(formattedMessage, entry);
        } catch (err) {
          console.error(`Error in transport ${transport.constructor.name}:`, err);
        }
      }
    });
  }
  child(metadata: Record<string, any>): Logger {
    const childOptions: LoggerOptions = {
      level: this.options.level,
      levels: this.levels,
      transports: this.transports,
      metadata: { ...this.options.metadata, ...metadata },
      exitOnError: this.options.exitOnError,
    };
    return new Logger(childOptions);
  }
  close(): void {
    Promise.all(
      this.transports.map((transport) => {
        if (typeof transport.close === 'function') {
          try {
            return transport.close();
          } catch (err) {
            console.error(`Error closing transport ${transport.constructor.name}:`, err);
            return Promise.resolve();
          }
        }
        return Promise.resolve();
      }),
    ).catch((err) => {
      console.error('Error during logger close:', err);
    });
  }
}
const defaultLogFilePath = process.env.LOG_FILE_PATH || path.join(process.cwd(), 'logs/app.log');
const defaultLogger = new Logger({
  level: (process.env.LOG_LEVEL as LogLevel) || 'info',
  transports: [
    new ConsoleTransport({
      formatter: new PrettyFormatter({
        useColors: true,
        useBoxes: true,
        showTimestamp: false,
      }),
      level: (process.env.CONSOLE_LOG_LEVEL as LogLevel) || undefined,
    }),
    new FileTransport({
      filename: defaultLogFilePath,
      formatter: new PrettyFormatter({
        useColors: false,
        useBoxes: false,
        showTimestamp: true,
      }),
      level: (process.env.FILE_LOG_LEVEL as LogLevel) || undefined,
    }),
  ],
});
export default defaultLogger;
export { standardLevels };
</file>

<file path="utils/mimeTypes.ts">
export const mimeTypes: Record<string, string> = {
  '.html': 'text/html',
  '.htm': 'text/html',
  '.js': 'application/javascript',
  '.json': 'application/json',
  '.css': 'text/css',
  '.txt': 'text/plain',
  '.jpg': 'image/jpeg',
  '.jpeg': 'image/jpeg',
  '.png': 'image/png',
  '.gif': 'image/gif',
  '.svg': 'image/svg+xml',
  '.ico': 'image/x-icon',
  '.mp3': 'audio/mpeg',
  '.mp4': 'video/mp4',
  '.webm': 'video/webm',
  '.ogg': 'audio/ogg',
  '.pdf': 'application/pdf',
  '.zip': 'application/zip',
  '.tar': 'application/x-tar',
};
</file>

<file path="main.ts">
import './routes';
import { HttpServer } from './core/server';
import { config } from './config/server.config';
import logger from './utils/logger';
logger.child([JSON.stringify(config, null, 2)]).info('routes loaded');
const server = new HttpServer(config.port);
server.start();
</file>

<file path="embedding_service_helper.py">
import logging
import sys
import os
import json
from PIL import Image
import torch
import signal
PY_LOG_PREFIX = "[PyEmbeddingHelper]"
class StructuredFormatter(logging.Formatter):
    def format(self, record):
        base = {
            "prefix": PY_LOG_PREFIX,
            "level": record.levelname,
            "time": self.formatTime(record, self.datefmt),
            "file": record.pathname,
            "func": record.funcName,
            "line": record.lineno,
            "msg": record.getMessage(),
        }
        if record.exc_info:
            base["exc"] = self.formatException(record.exc_info)
        return json.dumps(base)
console_handler = logging.StreamHandler(sys.stderr)
console_handler.setFormatter(
    logging.Formatter(
        f"{PY_LOG_PREFIX} %(asctime)s %(levelname)s %(funcName)s: %(message)s",
        "%Y-%m-%d %H:%M:%S",
    )
)
log_file_path = os.path.join(
    os.path.dirname(__file__), "._" + os.path.basename(__file__) + ".log"
)
file_handler = logging.FileHandler(log_file_path)
file_handler.setFormatter(StructuredFormatter())
root_logger = logging.getLogger()
root_logger.setLevel(logging.DEBUG)
root_logger.handlers = [console_handler, file_handler]
logging.getLogger("transformers").setLevel(logging.CRITICAL)
logging.getLogger("urllib3").setLevel(logging.CRITICAL)
logging.getLogger("huggingface_hub").setLevel(logging.CRITICAL)
logging.getLogger().setLevel(logging.ERROR)
def handle_sigint(signum, frame):
    logging.getLogger(__name__).info("Received SIGINT (Ctrl+C). Exiting gracefully.")
    sys.exit(0)
def handle_sigterm(signum, frame):
    logging.getLogger(__name__).info("Received SIGTERM. Exiting gracefully.")
    sys.exit(0)
signal.signal(signal.SIGINT, handle_sigint)
signal.signal(signal.SIGTERM, handle_sigterm)
from transformers import CLIPProcessor, CLIPModel
import math
import subprocess
import concurrent.futures
import io
from contextlib import nullcontext
IMAGE_EXTS = [".jpg", ".jpeg", ".png", ".webp", ".avif", ".gif"]
VIDEO_EXTS = [".mp4", ".mov", ".webm", ".ogg", ".m4v"]
def compute_entropy(image: Image.Image) -> float:
    grayscale = image.convert("L")
    histogram = grayscale.histogram()
    total_pixels = sum(histogram)
    entropy = 0.0
    for count in histogram:
        if count > 0:
            p = count / total_pixels
            entropy -= p * math.log(p, 2)
    return entropy
class VideoProcessor:
    def __init__(self, video_path: str, num_frames: int, logger=None, executor=None):
        self.video_path = video_path
        self.num_frames = num_frames
        self.logger = logger or logging.getLogger(__name__)
        self.duration = self.get_duration()
        self.executor = executor
    def get_duration(self) -> float:
        self.logger.debug(
            f"Calling ffprobe to get duration for video: {self.video_path}"
        )
        try:
            result = subprocess.run(
                [
                    "ffprobe",
                    "-v",
                    "error",
                    "-show_entries",
                    "format=duration",
                    "-of",
                    "default=noprint_wrappers=1:nokey=1",
                    self.video_path,
                ],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=True,
            )
            duration = float(result.stdout.strip())
            self.logger.debug(f"Video duration: {duration} seconds")
            return duration
        except Exception as e:
            self.logger.error("Failed to get video duration", exc_info=True)
            raise RuntimeError(f"Failed to get video duration: {e}")
    def get_advanced_sample_times(self) -> tuple:
        candidate_times = None
        debug_metadata = {}
        method_used = ""
        try:
            from scenedetect import VideoManager, SceneManager
            from scenedetect.detectors import ContentDetector
            video_manager = VideoManager([self.video_path])
            scene_manager = SceneManager()
            scene_manager.add_detector(ContentDetector(threshold=25, min_scene_len=10))
            video_manager.start()
            scene_manager.detect_scenes(frame_source=video_manager, show_progress=True)
            scene_list = scene_manager.get_scene_list()
            candidate_times = [
                (scene[0].get_seconds() + scene[1].get_seconds()) / 2
                for scene in scene_list
            ]
            debug_metadata["scene_count"] = len(scene_list)
            method_used = "scene_detection"
            self.logger.debug(f"Detected {len(scene_list)} scenes.")
            if (
                len(candidate_times)
                < self.num_frames
                or len(scene_list) < (self.num_frames // 2)
                or self.duration
                < (self.num_frames * 2)
            ):
                self.logger.warning(
                    "Insufficient scene coverage or short video; falling back to uniform sampling."
                )
                candidate_times = None
        except Exception as e:
            self.logger.warning(
                "Scene detection failed or PySceneDetect not installed; falling back to dense candidate extraction.",
                exc_info=True,
            )
        if not candidate_times or len(candidate_times) < self.num_frames:
            candidate_times = [
                (i + 1) * self.duration / (self.num_frames + 1)
                for i in range(self.num_frames)
            ]
            method_used = "fallback_uniform"
            debug_metadata = {"method_used": method_used, "timestamps": candidate_times}
            return candidate_times, debug_metadata
        candidate_frames = []
        executor = self.executor or concurrent.futures.ThreadPoolExecutor()
        with executor if self.executor is None else nullcontext(executor):
            future_to_time = {
                executor.submit(self.extract_frame, t): t for t in candidate_times
            }
            for future in concurrent.futures.as_completed(future_to_time):
                t = future_to_time[future]
                try:
                    frame = future.result()
                    candidate_frames.append((t, frame))
                except Exception as e:
                    self.logger.error(
                        f"Failed to extract candidate frame at {t} sec: {e}"
                    )
        if not candidate_frames:
            uniform_times = [
                (i + 1) * self.duration / (self.num_frames + 1)
                for i in range(self.num_frames)
            ]
            debug_metadata = {
                "method_used": "fallback_uniform_extraction",
                "timestamps": uniform_times,
            }
            return uniform_times, debug_metadata
        entropy_values = []
        for t, frame in candidate_frames:
            try:
                entropy_val = compute_entropy(frame)
            except Exception as e:
                entropy_val = 0.0
            entropy_values.append((t, entropy_val))
        debug_metadata["entropy_values"] = entropy_values
        entropy_values.sort(key=lambda x: x[1], reverse=True)
        selected = []
        diversity_threshold = (
            self.duration * 0.05
        )
        for t, entropy_val in entropy_values:
            if not selected or all(abs(t - s) > diversity_threshold for s in selected):
                selected.append(t)
            if len(selected) == self.num_frames:
                break
        debug_metadata["selected_entropy_values"] = [
            (t, entropy_val) for t, entropy_val in entropy_values if t in selected
        ]
        if len(selected) < self.num_frames:
            remaining = sorted([t for t, _ in entropy_values if t not in selected])
            for t in remaining:
                if len(selected) < self.num_frames:
                    selected.append(t)
        selected.sort()
        debug_metadata["selected_times"] = selected
        debug_metadata["method_used"] = method_used
        return selected, debug_metadata
    def extract_frame(self, time_sec: float) -> Image.Image:
        command = [
            "ffmpeg",
            "-y",
            "-ss",
            str(time_sec),
            "-i",
            self.video_path,
            "-vframes",
            "1",
            "-f",
            "image2pipe",
            "-vcodec",
            "mjpeg",
            "-",
        ]
        self.logger.debug(
            f"Calling ffmpeg to extract frame at {time_sec} seconds from video: {self.video_path}"
        )
        try:
            result = subprocess.run(
                command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True
            )
            if not result.stdout:
                raise RuntimeError("No frame data returned from ffmpeg.")
            image = Image.open(io.BytesIO(result.stdout)).convert("RGB")
            self.logger.debug(f"Extracted frame at {time_sec} seconds")
            return image
        except Exception as e:
            self.logger.error(
                f"Frame extraction failed at {time_sec} sec", exc_info=True
            )
            raise RuntimeError(f"Failed to extract frame at {time_sec} sec: {e}")
    def extract_frames(self) -> tuple:
        timestamps, debug_metadata = self.get_advanced_sample_times()
        frames = []
        executor = self.executor or concurrent.futures.ThreadPoolExecutor()
        with executor if self.executor is None else nullcontext(executor):
            future_to_time = {
                executor.submit(self.extract_frame, t): t for t in timestamps
            }
            for future in concurrent.futures.as_completed(future_to_time):
                t = future_to_time[future]
                try:
                    frame = future.result()
                    frames.append((t, frame))
                except Exception as e:
                    self.logger.error(f"Failed to extract frame at {t} sec: {e}")
        if not frames:
            raise RuntimeError("No frames extracted from video.")
        frames.sort(key=lambda x: x[0])
        return [frame for _, frame in frames], debug_metadata
class CLIPEmbedder:
    def __init__(
        self,
        model_name="openai/clip-vit-base-patch32",
        device=None,
        logger=None,
        enable_augmentation=False,
    ):
        self.logger = logger
        if device is None:
            if torch.backends.mps.is_available():
                self.device = "mps"
            elif torch.cuda.is_available():
                self.device = "cuda"
            else:
                self.device = "cpu"
        else:
            self.device = device
        self.model = CLIPModel.from_pretrained(model_name).to(self.device)
        self.processor = CLIPProcessor.from_pretrained(model_name)
        self.enable_augmentation = enable_augmentation
        if enable_augmentation:
            import torchvision.transforms as T
            self.augmentation_transforms = T.Compose(
                [
                    T.RandomResizedCrop((224, 224), scale=(0.8, 1.0)),
                    T.RandomHorizontalFlip(p=0.5),
                ]
            )
        else:
            self.augmentation_transforms = None
    def get_image_embedding(self, image: Image.Image) -> list:
        if self.enable_augmentation:
            image = self.augmentation_transforms(image)
        inputs = self.processor(images=image, return_tensors="pt").to(self.device)
        with torch.no_grad():
            image_features = self.model.get_image_features(**inputs)
        image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)
        return image_features[0].cpu().numpy().tolist()
    def get_video_embedding(self, frames: list) -> list:
        if self.enable_augmentation:
            frames = [self.augmentation_transforms(f) for f in frames]
        inputs = self.processor(images=frames, return_tensors="pt", padding=True).to(
            self.device
        )
        with torch.no_grad():
            image_features = self.model.get_image_features(**inputs)
        image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)
        averaged_embedding = image_features.mean(dim=0)
        return averaged_embedding.cpu().numpy().tolist()
def compute_single_embedding(fp, args, embedder, executor=None):
    import logging
    import os
    import time
    ext = os.path.splitext(fp)[1].lower()
    logger = logging.getLogger(__name__)
    try:
        debug_metadata = {
            "model": getattr(args, "model", None),
            "num_frames": (
                getattr(args, "num_frames", None) if ext in VIDEO_EXTS else None
            ),
            "enable_augmentation": getattr(args, "enable_augmentation", False),
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        }
        if ext in VIDEO_EXTS:
            from io import BytesIO
            import subprocess
            logger.debug(f"Preparing to process video file: {fp}")
            video_processor = VideoProcessor(
                fp, args.num_frames, logger=logger, executor=executor
            )
            frames, adv_debug = video_processor.extract_frames()
            embedding = embedder.get_video_embedding(frames)
            debug_metadata.update(adv_debug)
            result = {
                "embedding": embedding,
                "debugMetadata": debug_metadata,
                "error": None,
                "detail": None,
            }
        elif ext in IMAGE_EXTS:
            logger.debug(f"Opening image file: {fp}")
            image = Image.open(fp).convert("RGB")
            embedding = embedder.get_image_embedding(image)
            result = {
                "embedding": embedding,
                "debugMetadata": debug_metadata,
                "error": None,
                "detail": None,
            }
        else:
            logger.error("Unsupported file type")
            result = {
                "embedding": None,
                "debugMetadata": debug_metadata,
                "error": "Unsupported file type",
                "detail": f"File type not supported: {ext} for file {fp}",
            }
        return result
    except Exception as e:
        logger.exception("An error occurred during processing.")
        return {
            "embedding": None,
            "debugMetadata": debug_metadata if "debug_metadata" in locals() else {},
            "error": "Processing failed",
            "detail": f"{type(e).__name__}: {e} (file: {fp})",
        }
def process_batch(image_paths, embedder, args, logger, shared_executor):
    results = {}
    total = len(image_paths)
    processed = 0
    for fp in image_paths:
        logger.debug(f"Processing file: {fp}")
        if not os.path.exists(fp):
            logger.error(f"Missing file: {fp}")
            results[fp] = {
                "embedding": None,
                "debugMetadata": {},
                "error": "File does not exist",
                "detail": f"Path not found: {fp}",
            }
            processed += 1
            print(
                f"PROGRESS: "
                + json.dumps({"processed": processed, "total": total, "current": fp}),
                file=sys.stderr,
                flush=True,
            )
            continue
        result = compute_single_embedding(fp, args, embedder, shared_executor)
        if "error" in result and "detail" not in result:
            result["detail"] = f"Failed to process file: {fp}"
        for k in ["embedding", "debugMetadata", "error", "detail"]:
            if k not in result:
                result[k] = None
        results[fp] = result
        processed += 1
        print(
            f"PROGRESS: "
            + json.dumps({"processed": processed, "total": total, "current": fp}),
            file=sys.stderr,
            flush=True,
        )
    return results
def main_service():
    import sys
    import argparse
    import logging
    parser = argparse.ArgumentParser(
        description="CLIP embedding service (stdin/stdout)"
    )
    parser.add_argument("--model", type=str, default="openai/clip-vit-base-patch32")
    parser.add_argument("-n", "--num_frames", type=int, default=20)
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--log", action="store_true")
    parser.add_argument("--enable_augmentation", action="store_true", default=False)
    args = parser.parse_args()
    logging.basicConfig(
        level=logging.DEBUG,
        format="[%(asctime)s] %(levelname)s %(name)s: %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        stream=sys.stderr,
    )
    logger = logging.getLogger(__name__)
    logger.info("CLIP embedding service started. Waiting for input...")
    embedder = CLIPEmbedder(
        model_name=args.model,
        device=None,
        logger=logger,
        enable_augmentation=args.enable_augmentation,
    )
    logger.info(f"CLIPEmbedder initialized on device: {embedder.device}")
    shared_executor = concurrent.futures.ThreadPoolExecutor()
    while True:
        try:
            line = sys.stdin.readline()
            if not line:
                break
            line = line.strip()
            if not line:
                continue
            try:
                request = json.loads(line)
                image_paths = request.get("imagePaths")
                if not isinstance(image_paths, list):
                    raise ValueError("'imagePaths' must be a list.")
            except Exception as e:
                error_response = {"error": "Invalid input", "detail": str(e)}
                print(json.dumps(error_response), flush=True)
                continue
            try:
                results = process_batch(
                    image_paths, embedder, args, logger, shared_executor
                )
                print(json.dumps(results), flush=True)
            except Exception as e:
                batch_error = {
                    "batchError": str(e),
                    "detail": f"{type(e).__name__}: {e}",
                }
                print(json.dumps(batch_error), flush=True)
                continue
        except Exception as e:
            logger.error(f"Fatal error in main loop: {e}", exc_info=True)
            break
if __name__ == "__main__":
    main_service()
</file>

<file path="requirements.txt">
pillow
torch
scenedetect
torchvision
transformers
</file>

<file path="__mocks__/logger.ts">
module.exports = {
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
};
</file>

<file path="core/httpParser.test.ts">
import { HttpRequestParser } from '../../src/core/httpParser';
import { IncomingRequest } from '../../src/entities/http';
function feedAll(parser: HttpRequestParser, str: string): IncomingRequest | null {
  return parser.feed(Buffer.from(str, 'utf8'));
}
describe('HttpRequestParser', () => {
  let parser: HttpRequestParser;
  beforeEach(() => {
    parser = new HttpRequestParser();
  });
  test('parses simple GET request', () => {
    const req = feedAll(parser, 'GET /hello HTTP/1.1\r\nHost: example.com\r\n\r\n');
    expect(req).not.toBeNull();
    expect(req?.method).toBe('GET');
    expect(req?.path).toBe('/hello');
    expect(req?.headers['host']).toBe('example.com');
    expect(req?.invalid).toBeFalsy();
  });
  test('parses POST with Content-Length', () => {
    const req = feedAll(
      parser,
      'POST /submit HTTP/1.1\r\nHost: test\r\nContent-Length: 11\r\n\r\nHello World',
    );
    expect(req).not.toBeNull();
    expect(req?.method).toBe('POST');
    expect(req?.body?.toString()).toBe('Hello World');
  });
  test('handles chunked transfer-encoding', () => {
    const parts = [
      'POST /upload HTTP/1.1\r\nHost: test\r\nTransfer-Encoding: chunked\r\n\r\n',
      '5\r\nHello\r\n',
      '6\r\n World\r\n',
      '0\r\n\r\n',
    ];
    let result: IncomingRequest | null = null;
    for (const p of parts) {
      const feedResult = parser.feed(Buffer.from(p, 'utf8'));
      if (feedResult) result = feedResult;
    }
    if (!result) {
      const feedResult = parser.feed(Buffer.alloc(0));
      if (feedResult) result = feedResult;
    }
    expect(result).not.toBeNull();
    expect(result?.body?.toString()).toBe('Hello World');
  });
  test('rejects invalid request line', () => {
    const req = feedAll(parser, 'BADREQUEST\r\nHost: test\r\n\r\n');
    expect(req).not.toBeNull();
    expect(req?.invalid).toBeTruthy();
  });
  test('rejects unsupported HTTP method', () => {
    const req = feedAll(parser, 'FOO / HTTP/1.1\r\nHost: test\r\n\r\n');
    expect(req).not.toBeNull();
    expect(req?.invalid).toBeTruthy();
  });
  test('rejects too many headers', () => {
    const headers = Array(1005).fill('X-Test: 123').join('\r\n');
    const req = feedAll(parser, `GET / HTTP/1.1\r\n${headers}\r\n\r\n`);
    expect(req).not.toBeNull();
    expect(req?.invalid).toBeTruthy();
  });
  test('rejects body exceeding MAX_BODY_BYTES', () => {
    const bigBody = 'A'.repeat(11 * 1024 * 1024);
    const req = feedAll(
      parser,
      `POST / HTTP/1.1\r\nHost: test\r\nContent-Length: ${bigBody.length}\r\n\r\n${bigBody}`,
    );
    expect(req).not.toBeNull();
    expect(req?.invalid).toBeTruthy();
  });
  test('parses partial requests across multiple TCP chunks', () => {
    const req1 = parser.feed(Buffer.from('GET /mul', 'utf8'));
    expect(req1).toBeNull();
    const req2 = parser.feed(Buffer.from('ti-part HTTP/1.1\r\nHost: te', 'utf8'));
    expect(req2).toBeNull();
    const req3 = parser.feed(Buffer.from('st\r\n\r\n', 'utf8'));
    expect(req3).not.toBeNull();
    expect(req3?.method).toBe('GET');
    expect(req3?.path).toBe('/multi-part');
    expect(req3?.headers['host']).toBe('test');
  });
  test('parses headers with continuations', () => {
    const req = feedAll(
      parser,
      'GET / HTTP/1.1\r\nHost: test\r\nX-Long-Header: abc\r\n def\r\n\r\n',
    );
    expect(req).not.toBeNull();
    expect(req?.headers['x-long-header']).toBe('abc def');
  });
  test('ignores trailers after chunked body', () => {
    const parts = [
      'POST /upload HTTP/1.1\r\nHost: test\r\nTransfer-Encoding: chunked\r\n\r\n',
      '5\r\nHello\r\n',
      '6\r\n World\r\n',
      '0\r\nSome-Trailer: yes\r\n\r\n',
    ];
    let result: IncomingRequest | null = null;
    for (const p of parts) {
      const feedResult = parser.feed(Buffer.from(p, 'utf8'));
      if (feedResult) result = feedResult;
    }
    expect(result).not.toBeNull();
    expect(result?.body?.toString()).toBe('Hello World');
  });
  test('rejects missing Host header in HTTP/1.1', () => {
    const req = feedAll(parser, 'GET /test HTTP/1.1\r\n\r\n');
    expect(req).not.toBeNull();
    expect(req?.invalid).toBeTruthy();
  });
  test('allows HTTP/1.0 without Host header', () => {
    const req = feedAll(parser, 'GET /test HTTP/1.0\r\n\r\n');
    expect(req).not.toBeNull();
    expect(req?.invalid).toBeFalsy();
  });
});
</file>

<file path="core/parser.test.ts">
import { parser } from '../../src/core/parser';
describe('HTTP Parser', () => {
  it('should parse a simple GET request', () => {
    const raw = 'GET /hello HTTP/1.1\r\nHost: localhost\r\nUser-Agent: test\r\n\r\n';
    const parsed = parser.parse(raw);
    expect(parsed.method).toBe('GET');
    expect(parsed.path).toBe('/hello');
    expect(parsed.httpVersion).toBe('HTTP/1.1');
    expect(parsed.headers.host).toBe('localhost');
    expect(parsed.headers['user-agent']).toBe('test');
  });
  it('should handle missing headers gracefully', () => {
    const raw = 'POST /upload HTTP/1.1\r\n\r\n';
    const parsed = parser.parse(raw);
    expect(parsed.method).toBe('POST');
    expect(parsed.path).toBe('/upload');
    expect(parsed.headers).toEqual({});
  });
  it('should not crash on completely malformed request', () => {
    const raw = 'INVALID REQUEST';
    const parsed = parser.parse(raw);
    expect(parsed.invalid).toBe(true);
    expect(parsed.method).toBeFalsy();
    expect(parsed.path).toBeFalsy();
  });
  it('should parse url.pathname and headersMap correctly', () => {
    const raw = 'GET /hello HTTP/1.1\r\nHost: localhost\r\nUser-Agent: test\r\n\r\n';
    const parsed = parser.parse(raw);
    expect(parsed.url?.pathname).toBe('/hello');
    expect(parsed.headersMap?.get('host')).toEqual(['localhost']);
  });
  it('exposes url, path, and query consistently', () => {
    const raw = 'GET /stream?file=test.mp4 HTTP/1.1\r\nHost: x\r\n\r\n';
    const r = parser.parse(raw);
    expect(r.url.pathname).toBe('/stream');
    expect(r.path).toBe('/stream');
    expect(r.query).toEqual({ file: 'test.mp4' });
  });
  it('includes httpVersion', () => {
    const raw = 'GET /test HTTP/1.1\r\nHost: x\r\n\r\n';
    const r = parser.parse(raw);
    expect(r.httpVersion).toBe('HTTP/1.1');
  });
  it('should handle completely empty request', () => {
    const raw = '';
    const parsed = parser.parse(raw);
    expect(parsed.invalid).toBe(true);
    expect(parsed.method).toBeFalsy();
    expect(parsed.path).toBeFalsy();
    expect(parsed.headers).toEqual({});
  });
  it('should correctly parse multiple query parameters', () => {
    const raw = 'GET /search?q=nodejs&sort=desc HTTP/1.1\r\nHost: localhost\r\n\r\n';
    const parsed = parser.parse(raw);
    expect(parsed.method).toBe('GET');
    expect(parsed.path).toBe('/search');
    expect(parsed.httpVersion).toBe('HTTP/1.1');
    expect(parsed.headers.host).toBe('localhost');
    expect(parsed.query).toEqual({ q: 'nodejs', sort: 'desc' });
  });
  it('should decode percent-encoded paths', () => {
    const raw = 'GET /foo%20bar HTTP/1.1\r\nHost: localhost\r\n\r\n';
    const parsed = parser.parse(raw);
    expect(parsed.path).toBe('/foo bar');
  });
  it('should handle OPTIONS * request', () => {
    const raw = 'OPTIONS * HTTP/1.1\r\nHost: localhost\r\n\r\n';
    const parsed = parser.parse(raw);
    expect(parsed.method).toBe('OPTIONS');
    expect(parsed.path).toBe('*');
  });
  it('should handle duplicated headers gracefully', () => {
    const raw = `GET / HTTP/1.1\r\nHost: localhost\r\nCookie: a=1\r\nCookie: b=2\r\n\r\n`;
    const parsed = parser.parse(raw);
    expect(parsed.headers.host).toBe('localhost');
    expect(parsed.headers['cookie']).toBe('b=2');
    expect(parsed.headersMap?.get('cookie')).toEqual(['a=1', 'b=2']);
  });
});
</file>

<file path="core/router.test.ts">
import { Socket } from 'net';
import { createRouter } from '../../src/core/router';
import { sendResponse } from '../../src/entities/sendResponse';
import type { IncomingRequest } from '../../src/entities/http';
jest.mock('../../src/entities/sendResponse');
jest.mock('../../src/utils/logger', () => {
  return {
    Logger: jest.fn().mockImplementation(() => ({
      info: jest.fn(),
      error: jest.fn(),
      warn: jest.fn(),
    })),
    ConsoleTransport: jest.fn(),
    FileTransport: jest.fn(),
    PrettyFormatter: jest.fn(),
  };
});
describe('Router', () => {
  let router;
  let socket: Socket;
  let req: IncomingRequest;
  beforeEach(() => {
    router = createRouter();
    socket = {
      write: jest.fn(),
      end: jest.fn(),
      destroy: jest.fn(),
    } as unknown as Socket;
    req = {
      method: 'GET',
      path: '/test',
      query: {},
      httpVersion: 'HTTP/1.1',
      headers: {},
      headersMap: new Map(),
      url: new URL('http://localhost/test'),
      raw: '',
      ctx: {},
      invalid: false,
    };
  });
  afterEach(() => {
    jest.clearAllMocks();
  });
  test('should run middleware in sequence', async () => {
    const order: string[] = [];
    router.use(async (_req, _sock, next) => {
      order.push('mw1');
      await next();
      order.push('mw1-after');
    });
    router.use(async (_req, _sock, next) => {
      order.push('mw2');
      await next();
      order.push('mw2-after');
    });
    router.any('/test', async () => {
      order.push('handler');
    });
    await router.handle(req, socket);
    expect(order).toEqual(['mw1', 'mw2', 'handler', 'mw2-after', 'mw1-after']);
  });
  test('should call matching handler for GET route', async () => {
    const handler = jest.fn();
    router.get('/test', handler);
    await router.handle(req, socket);
    expect(handler).toHaveBeenCalledWith(req, socket);
  });
  test('should respond with 404 if no route matches', async () => {
    req.path = '/unknown';
    await router.handle(req, socket);
    expect(sendResponse).toHaveBeenCalledWith(
      socket,
      404,
      { 'Content-Type': 'text/plain' },
      'Not Found',
    );
  });
  test('should respond with 405 if method does not match', async () => {
    req.method = 'POST';
    router.get('/test', jest.fn());
    await router.handle(req, socket);
    expect(sendResponse).toHaveBeenCalledWith(socket, 405, { Allow: 'GET' }, 'Method Not Allowed');
  });
  test('should extract params into req.ctx.params', async () => {
    const paramHandler = jest.fn();
    router.get('/users/:id', paramHandler);
    req.path = '/users/123';
    req.url = new URL('http://localhost/users/123');
    await router.handle(req, socket);
    expect(paramHandler).toHaveBeenCalled();
    expect(req.ctx?.params).toEqual({ id: '123' });
  });
  test('should respond with 500 on handler error', async () => {
    router.get('/error', () => {
      throw new Error('fail');
    });
    req.path = '/error';
    req.url = new URL('http://localhost/error');
    await router.handle(req, socket);
    expect(sendResponse).toHaveBeenCalledWith(
      socket,
      500,
      { 'Content-Type': 'text/plain' },
      '500 Server Error',
    );
  });
  test('should respond to OPTIONS with Allow header', async () => {
    req.method = 'OPTIONS';
    req.path = '/anything';
    await router.handle(req, socket);
    expect(sendResponse).toHaveBeenCalledWith(
      socket,
      200,
      { 'Content-Type': 'text/plain', Allow: 'GET, POST, PUT, DELETE, OPTIONS' },
      'OK',
    );
  });
});
</file>

<file path="core/server.test.ts">
import { createServer, Socket } from 'net';
import { HttpServer } from '../../src/core/server';
import { sendResponse } from '../../src/entities/sendResponse';
import logger from '../../src/utils/logger';
import { config } from '../../src/config/server.config';
import * as RouterModule from '../../src/core/router';
import { HttpRequestParser } from '../../src/core/httpParser';
jest.mock('net');
jest.mock('../../src/utils/logger');
jest.mock('../../src/entities/sendResponse');
jest.mock('../../src/config/server.config', () => ({
  config: {
    headerTimeoutMs: 100,
    bodyTimeoutMs: 100,
  },
}));
describe('HttpServer', () => {
  let server: HttpServer;
  let mockSocket: Socket;
  let mockNetServer: any;
  let parserInstance: any;
  let realRouter: any;
  beforeEach(() => {
    jest.clearAllMocks();
    mockSocket = {
      on: jest.fn(),
      once: jest.fn(),
      write: jest.fn(),
      end: jest.fn(),
      destroy: jest.fn(),
    } as unknown as Socket;
    parserInstance = new HttpRequestParser();
    mockNetServer = {
      on: jest.fn(),
      listen: jest.fn(),
      close: jest.fn((cb: () => void) => cb()),
    };
    (createServer as jest.Mock).mockReturnValue(mockNetServer);
    realRouter = RouterModule.createRouter();
    jest.spyOn(realRouter, 'handle').mockImplementation(jest.fn());
    server = new HttpServer(3000, realRouter);
  });
  test('should listen on provided port', () => {
    server.start();
    expect(mockNetServer.listen).toHaveBeenCalledWith(3000, expect.any(Function));
  });
  test('should destroy sockets on stop()', async () => {
    const destroySpy = jest.spyOn(mockSocket, 'destroy');
    (server as any).connections.add(mockSocket);
    await server.stop();
    expect(destroySpy).toHaveBeenCalled();
    expect(mockNetServer.close).toHaveBeenCalled();
  });
  test('should handle incoming connection and process data', async () => {
    let dataHandler;
    mockSocket.on = jest.fn().mockImplementation((event, cb) => {
      if (event === 'data') dataHandler = cb;
    });
    mockSocket.once = jest.fn();
    const connHandler = mockNetServer.on.mock.calls.find(([evt]) => evt === 'connection')[1];
    connHandler(mockSocket);
    const handleSpy = jest.spyOn(realRouter, 'handle');
    dataHandler(Buffer.from('GET / HTTP/1.1\r\nHost: localhost\r\n\r\n'));
    expect(handleSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        method: 'GET',
        path: '/',
        invalid: false,
      }),
      mockSocket,
    );
  });
  test('should destroy socket on header timeout', () => {
    let timeoutFn;
    global.setTimeout = jest.fn((fn) => {
      timeoutFn = fn;
      return 123;
    }) as any;
    global.clearTimeout = jest.fn();
    mockSocket.once = jest.fn();
    mockSocket.on = jest.fn();
    const connHandler = mockNetServer.on.mock.calls.find(([evt]) => evt === 'connection')[1];
    connHandler(mockSocket);
    expect(setTimeout).toHaveBeenCalled();
    expect(typeof timeoutFn).toBe('function');
    timeoutFn();
    expect(mockSocket.destroy).toHaveBeenCalled();
  });
  test('should destroy socket on body timeout for POST request', async () => {
    let dataHandler;
    mockSocket.on = jest.fn().mockImplementation((event, cb) => {
      if (event === 'data') dataHandler = cb;
    });
    mockSocket.once = jest.fn();
    const connHandler = mockNetServer.on.mock.calls.find(([evt]) => evt === 'connection')[1];
    connHandler(mockSocket);
    let bodyTimeoutFn;
    global.setTimeout = jest.fn((fn) => {
      if (!bodyTimeoutFn) bodyTimeoutFn = fn;
      return 123;
    }) as any;
    global.clearTimeout = jest.fn();
    dataHandler(Buffer.from('POST / HTTP/1.1\r\n\r\n'));
    expect(typeof bodyTimeoutFn).toBe('function');
    bodyTimeoutFn();
    expect(mockSocket.destroy).toHaveBeenCalled();
  });
  test('should handle multiple pipelined requests in sequence', async () => {
    let dataHandler;
    mockSocket.on = jest.fn().mockImplementation((event, cb) => {
      if (event === 'data') dataHandler = cb;
    });
    mockSocket.once = jest.fn();
    const connHandler = mockNetServer.on.mock.calls.find(([evt]) => evt === 'connection')[1];
    connHandler(mockSocket);
    const handleSpy = jest.spyOn(realRouter, 'handle');
    dataHandler(Buffer.from('GET /first HTTP/1.1\r\n\r\n'));
    dataHandler(Buffer.from('GET /second HTTP/1.1\r\n\r\n'));
    expect(handleSpy).toHaveBeenCalledTimes(2);
  });
});
</file>

<file path="entities/sendResponse.test.ts">
import { sendResponse } from '../../src/entities/sendResponse';
import { Socket } from 'net';
import { Readable, Writable } from 'stream';
describe('sendResponse', () => {
  let socket: jest.Mocked<Socket>;
  beforeEach(() => {
    socket = new Writable({
      write(chunk, encoding, callback) {
        callback();
      },
    }) as jest.Mocked<Socket>;
    socket.write = jest.fn();
    socket.destroy = jest.fn();
  });
  test('writes headers only if no body', () => {
    sendResponse(socket, 200, { 'Content-Type': 'text/plain' });
    expect(socket.write).toHaveBeenCalledWith(
      expect.stringContaining('HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\n\r\n'),
    );
    expect(socket.write).toHaveBeenCalledTimes(1);
  });
  test('writes headers and string body', () => {
    sendResponse(socket, 200, { 'Content-Type': 'text/plain' }, 'Hello');
    expect(socket.write).toHaveBeenNthCalledWith(1, expect.stringContaining('HTTP/1.1 200 OK'));
    expect(socket.write).toHaveBeenNthCalledWith(2, 'Hello');
  });
  test('pipes readable body to socket', () => {
    const readable = new Readable();
    readable._read = () => {};
    readable.push('streamed');
    readable.push(null);
    const pipe = jest.spyOn(readable, 'pipe');
    sendResponse(socket, 200, {}, readable);
    expect(pipe).toHaveBeenCalledWith(socket, { end: false });
  });
  test('attaches error handler to stream', () => {
    const readable = new Readable();
    readable._read = () => {};
    const on = jest.spyOn(readable, 'once');
    sendResponse(socket, 200, {}, readable);
    expect(on).toHaveBeenCalledWith('error', expect.any(Function));
  });
  test('gracefully handles unknown status code', () => {
    sendResponse(socket, 499, { 'Content-Type': 'text/plain' }, 'Weird code');
    expect(socket.write).toHaveBeenCalledWith(expect.stringMatching(/^HTTP\/1.1 499 \r\n/));
  });
});
</file>

<file path="modules/app-metrics/metricsController.test.ts">
import router from '../../../src/core/router';
import { config } from '../../../src/config/server.config';
import { Socket } from 'net';
import { IncomingRequest } from '../../../src/entities/http';
describe('Metrics Endpoint (gallery-generator)', () => {
  let originalMetricsFeature: boolean;
  beforeAll(() => {
    originalMetricsFeature = config.features.metrics;
    config.features.metrics = true;
  });
  afterAll(() => {
    config.features.metrics = originalMetricsFeature;
  });
  it('should return 404 for unknown metrics app', async () => {
    const req: Omit<IncomingRequest, 'ctx'> & { ctx: Record<string, unknown> } = {
      method: 'POST',
      path: '/api/metrics/unknown-app',
      headers: { 'content-type': 'application/json' },
      body: Buffer.from(JSON.stringify({ event: 'test' })),
      ctx: {},
      url: new URL('http://localhost/api/metrics/unknown-app'),
      query: {},
      httpVersion: '1.1',
      raw: '', // Added raw request string
    };
    let responseCode = 0;
    let responseBody = '';
    const sock = {
      write: (data: string) => {
        const match = data.match(/HTTP\/1\.[01] (\d{3})/);
        if (match) responseCode = parseInt(match[1], 10);
        responseBody += data;
      },
      end: () => {},
    } as unknown as Socket;
    await router.handle(req, sock);
    expect(responseCode).toBe(404);
    expect(responseBody).toContain('Not Found');
  });
});
</file>

<file path="modules/file-hosting/fileHostingService.test.ts">
import { FileHostingService } from '../../../src/modules/file-hosting/fileHostingService';
import * as fs from 'fs';
import * as fsPromises from 'fs/promises';
jest.mock('fs');
jest.mock('fs/promises');
describe('FileHostingService', () => {
  let service: FileHostingService;
  beforeEach(() => {
    service = new FileHostingService('/mock/root');
  });
  test('resolveSafe throws on path traversal', () => {
    expect(() => service['resolveSafe']('../etc/passwd')).toThrow('Path traversal attempt');
  });
  test('listFiles calls readdir with safe path', async () => {
    (fsPromises.readdir as jest.Mock).mockResolvedValue(['file1.txt']);
    const result = await service.listFiles('.');
    expect(result).toEqual(['file1.txt']);
    expect(fsPromises.readdir).toHaveBeenCalledWith(expect.stringContaining('/mock/root'));
  });
  test('stat returns file stats from safe path', async () => {
    const fakeStat = { isFile: () => true };
    (fsPromises.stat as jest.Mock).mockResolvedValue(fakeStat);
    const result = await service.stat('data.txt');
    expect(result).toBe(fakeStat);
    expect(fsPromises.stat).toHaveBeenCalledWith(expect.stringContaining('/mock/root'));
  });
  test('readFile calls createReadStream with optional range', async () => {
    const createReadStream = fs.createReadStream as jest.Mock;
    await service.readFile('video.mp4', { start: 0, end: 100 });
    expect(createReadStream).toHaveBeenCalledWith(expect.stringContaining('video.mp4'), {
      start: 0,
      end: 100,
    });
  });
  test('saveFile writes data to file stream and ends it', async () => {
    const write = jest.fn();
    const end = jest.fn((cb) => cb());
    const on = jest.fn();
    const fakeStream = { write, end, on };
    (fs.createWriteStream as jest.Mock).mockReturnValue(fakeStream);
    (fsPromises.mkdir as jest.Mock).mockResolvedValue(undefined);
    const chunks = ['a', 'b'].map((x) => Buffer.from(x));
    const iterable = (async function* () {
      for (const chunk of chunks) yield chunk;
    })();
    await service.saveFile('upload.txt', iterable);
    expect(write).toHaveBeenCalledTimes(2);
    expect(end).toHaveBeenCalled();
    expect(fs.createWriteStream).toHaveBeenCalledWith(expect.stringContaining('upload.txt'));
  });
});
</file>

<file path="modules/file-streaming/fileStreamingController.test.ts">
import { fileStreamingController } from '../../../src/modules/file-streaming/fileStreamingController';
import { sendResponse } from '../../../src/entities/sendResponse';
import { FileHostingService } from '../../../src/modules/file-hosting/fileHostingService';
import logger from '../../../src/utils/logger';
import { Readable } from 'stream';
jest.mock('../../../src/entities/sendResponse');
jest.mock('../../../src/modules/file-hosting/fileHostingService');
jest.mock('../../../src/utils/logger');
const createMockReadable = () => {
  const stream = new Readable();
  stream._read = () => {};
  return stream;
};
describe('fileStreamingController.handleStream', () => {
  let req: any;
  let sock: any;
  beforeEach(() => {
    jest.clearAllMocks();
    req = {
      path: '/stream',
      query: {},
      headers: {},
      url: new URL('http://localhost/stream'),
    };
    sock = {
      end: jest.fn(),
      write: jest.fn(),
      destroy: jest.fn(),
    };
  });
  test('responds 400 if no file query provided', async () => {
    await fileStreamingController.handleStream(req, sock);
    expect(sendResponse).toHaveBeenCalledWith(
      sock,
      400,
      { 'Content-Type': 'text/plain' },
      'Missing required "file" query parameter.',
    );
  });
  test('responds 404 if file not found', async () => {
    req.query.file = 'nonexistent.mp4';
    (FileHostingService.prototype.stat as jest.Mock).mockRejectedValue(new Error('not found'));
    await fileStreamingController.handleStream(req, sock);
    expect(sendResponse).toHaveBeenCalledWith(
      sock,
      404,
      { 'Content-Type': 'text/plain' },
      expect.stringContaining('not found'),
    );
  });
  test('streams full file with 200 if no range', async () => {
    req.query.file = 'video.mp4';
    (FileHostingService.prototype.stat as jest.Mock).mockResolvedValue({ size: 1000 });
    const stream = createMockReadable();
    (FileHostingService.prototype.readFile as jest.Mock).mockResolvedValue(stream);
    await fileStreamingController.handleStream(req, sock);
    expect(sendResponse).toHaveBeenCalledWith(
      sock,
      200,
      expect.objectContaining({
        'Content-Type': expect.any(String),
        'Content-Length': '1000',
      }),
      stream,
    );
  });
  test('streams partial file with 206 if valid range', async () => {
    req.query.file = 'video.mp4';
    req.headers.range = 'bytes=0-499';
    (FileHostingService.prototype.stat as jest.Mock).mockResolvedValue({ size: 1000 });
    const stream = createMockReadable();
    (FileHostingService.prototype.readFile as jest.Mock).mockResolvedValue(stream);
    await fileStreamingController.handleStream(req, sock);
    expect(sendResponse).toHaveBeenCalledWith(
      sock,
      206,
      expect.objectContaining({
        'Content-Range': 'bytes 0-499/1000',
        'Content-Length': '500',
      }),
      stream,
    );
  });
  test('responds 416 if range invalid', async () => {
    req.query.file = 'video.mp4';
    req.headers.range = 'bytes=1500-1600';
    (FileHostingService.prototype.stat as jest.Mock).mockResolvedValue({ size: 1000 });
    await fileStreamingController.handleStream(req, sock);
    expect(sendResponse).toHaveBeenCalledWith(
      sock,
      416,
      { 'Content-Type': 'text/plain' },
      '416 Range Not Satisfiable',
    );
    expect(sock.end).toHaveBeenCalled();
  });
});
</file>

<file path="utils/helpers.test.ts">
import { getMimeType } from '../../src/utils/helpers';
describe('Helpers - getMimeType', () => {
  it('should return correct MIME type for mp4', () => {
    expect(getMimeType('movie.mp4')).toBe('video/mp4');
  });
  it('should return correct MIME type for jpg', () => {
    expect(getMimeType('image.jpg')).toBe('image/jpeg');
  });
  it('should return default MIME type for unknown file extension', () => {
    expect(getMimeType('something.unknownext')).toBe('application/octet-stream');
  });
  it('should return default MIME type for file with no extension', () => {
    expect(getMimeType('README')).toBe('application/octet-stream');
  });
});
</file>

<file path="global.d.ts">
export {};
</file>

<file path="setupJest.ts">
import 'jest-extended';
export const add = (a: number, b: number): number => {
  return a + b;
};
export const subtract = (a: number, b: number): number => {
  return a - b;
};
</file>

<file path="fileHosting.stress.test.ts">
import { FileHostingService } from '../src/modules/file-hosting/fileHostingService';
import * as fs from 'fs';
import * as fsPromises from 'fs/promises';
import { Writable } from 'stream';
import pLimit from 'p-limit';
jest.mock('fs');
jest.mock('fs/promises');
describe('FileHostingService Stress Test', () => {
  const limit = pLimit(50);
  const writeCalls: any[] = [];
  beforeEach(() => {
    jest.clearAllMocks();
    (fsPromises.mkdir as jest.Mock).mockResolvedValue(undefined);
    (fs.createWriteStream as jest.Mock).mockImplementation((path: string) => {
      if (path.includes('fail-fd')) {
        const err = new Error('Too many open files') as NodeJS.ErrnoException;
        err.code = 'EMFILE';
        throw err;
      }
      const writable = new Writable({
        write(chunk, _encoding, callback) {
          writeCalls.push(chunk.toString());
          callback();
        },
      });
      writable.on('error', jest.fn());
      writable.end = jest.fn((cb) => cb && cb());
      return writable;
    });
  });
  test('handles 1000 concurrent small uploads with disk delays and fd exhaustion', async () => {
    const service = new FileHostingService('/mock/root');
    const uploads = Array.from({ length: 1000 }).map((_, i) =>
      limit(async () => {
        const shouldFail = i % 20 === 0;
        const failFd = i % 25 === 0;
        const fileName = failFd ? `fail-fd-${i}.txt` : `upload-${i}.txt`;
        const chunks = [Buffer.from(`part1-${i}`), Buffer.from(`part2-${i}`)];
        const iterable = (async function* () {
          yield chunks[0];
          if (shouldFail) throw new Error(`Stream interrupted for ${i}`);
          yield chunks[1];
        })();
        try {
          await service.saveFile(fileName, iterable);
        } catch {
        }
      }),
    );
    await Promise.all(uploads);
    expect(fs.createWriteStream).toHaveBeenCalled();
    expect(writeCalls.length).toBeGreaterThan(1000);
  });
});
</file>

<file path="fileStreaming.stress.test.ts">
import { fileStreamingController } from '../src/modules/file-streaming/fileStreamingController';
import { FileHostingService } from '../src/modules/file-hosting/fileHostingService';
import { sendResponse } from '../src/entities/sendResponse';
import { Readable } from 'stream';
import pLimit from 'p-limit';
import { Socket } from 'net';
jest.mock('../src/modules/file-hosting/fileHostingService');
jest.mock('../src/entities/sendResponse');
describe('File Streaming Stress Test', () => {
  const dummyStream = () => {
    const stream = new Readable();
    stream._read = () => {
      stream.push(Buffer.alloc(1024));
      stream.push(null);
    };
    return stream;
  };
  const limit = pLimit(20);
  beforeEach(() => {
    jest.clearAllMocks();
    (FileHostingService.prototype.stat as jest.Mock).mockResolvedValue({ size: 10000 });
    (FileHostingService.prototype.readFile as jest.Mock).mockResolvedValue(dummyStream());
  });
  test('200 concurrent stream requests (full + range)', async () => {
    const tasks: Promise<void>[] = [];
    for (let i = 0; i < 200; i++) {
      const range = i % 2 === 0 ? undefined : `bytes=${i * 10}-${i * 10 + 999}`;
      const req = {
        method: 'GET',
        path: '/stream',
        query: { file: 'stress-test.mp4' },
        headers: { ...(range ? { range } : {}) } as Record<string, string>,
        httpVersion: '1.1',
        raw: '',
        url: new URL(`http://localhost/stream?file=stress-test.mp4`),
      };
      const sock = {
        write: jest.fn(),
        end: jest.fn(),
        destroy: jest.fn(),
      } as unknown as Socket;
      tasks.push(limit(() => fileStreamingController.handleStream(req, sock)));
    }
    await Promise.all(tasks);
    expect(sendResponse).toHaveBeenCalledTimes(200);
    const codes = (sendResponse as jest.Mock).mock.calls.map(([, code]) => code);
    expect(codes.filter((c) => c === 200).length).toBeGreaterThan(80);
    expect(codes.filter((c) => c === 206).length).toBeGreaterThan(80);
  });
});
</file>

<file path="router.stress.test.ts">
import { createRouter } from '../src/core/router';
import { Socket } from 'net';
describe('Router Stress Test', () => {
  let router: ReturnType<typeof createRouter>;
  let mockSocket: Socket;
  beforeEach(() => {
    router = createRouter();
    mockSocket = {
      write: jest.fn(),
      end: jest.fn(),
      destroy: jest.fn(),
    } as unknown as Socket;
  });
  test('handles 100 rapid requests across different routes', async () => {
    const results: string[] = [];
    const handler = jest.fn((req) => {
      results.push(`${req.method} ${req.path}`);
    });
    const middleware = jest.fn(async (req, sock, next) => {
      await next();
    });
    router.use(middleware);
    router.get('/a', handler);
    router.get('/b', handler);
    router.get('/c/:id', handler);
    const requests = Array.from({ length: 100 }).map((_, i) => {
      const path = i % 3 === 0 ? '/a' : i % 3 === 1 ? '/b' : `/c/${i}`;
      return {
        method: 'GET',
        path,
        query: {},
        headers: {},
        url: new URL(`http://localhost${path}`),
        ctx: {},
        httpVersion: 'HTTP/1.1',
        headersMap: new Map(),
        raw: '',
        invalid: false,
      };
    });
    await Promise.all(requests.map((req) => router.handle(req, mockSocket)));
    expect(handler).toHaveBeenCalledTimes(100);
    expect(middleware).toHaveBeenCalledTimes(100);
  });
});
</file>

<file path="server.stress.test.ts">
import { HttpServer } from '../src/core/server';
import { createRouter } from '../src/core/router';
import { Socket } from 'net';
import pLimit from 'p-limit';
describe('HttpServer Stress Test', () => {
  let server: HttpServer;
  let port: number;
  beforeAll(async () => {
    const router = createRouter();
    router.get('/ping', (req, sock) => {
      sock.write('HTTP/1.1 200 OK\r\nContent-Length: 2\r\n\r\nOK');
    });
    server = new HttpServer(0, router);
    await new Promise((resolve) => {
      server['server'].listen(0, () => {
        port = (server['server'].address() as any).port;
        resolve(null);
      });
    });
  });
  afterAll(async () => {
    await server.stop();
  });
  test('handles 500 concurrent TCP socket clients with throttling', async () => {
    const limit = pLimit(50);
    const results: Promise<string>[] = [];
    for (let i = 0; i < 500; i++) {
      results.push(
        limit(
          () =>
            new Promise((resolve, reject) => {
              const client = new Socket();
              let data = '';
              client.connect(port, '127.0.0.1', () => {
                client.write('GET /ping HTTP/1.1\r\nHost: localhost\r\n\r\n');
              });
              client.on('data', (chunk) => {
                data += chunk.toString();
                if (data.includes('OK')) {
                  client.end();
                  resolve(data);
                }
              });
              client.on('error', reject);
              client.on('end', () => {
                if (!data.includes('OK')) reject(new Error('Incomplete response'));
              });
            }),
        ),
      );
    }
    const responses = await Promise.all(results);
    expect(responses).toHaveLength(500);
    for (const res of responses) {
      expect(res).toContain('200 OK');
      expect(res).toContain('OK');
    }
  });
});
</file>

</files>
